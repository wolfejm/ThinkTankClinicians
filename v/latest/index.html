<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Melissa Treviño" />
  <meta name="author" content="Todd S. Horowitz" />
  <meta name="dcterms.date" content="2020-04-27" />
  <meta name="keywords" content="Medical image perception, Radiology, Pathology" />
  <title>The role and benefits of cognition and perception in medical imaging</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="The role and benefits of cognition and perception in medical imaging" />
  <meta name="citation_title" content="The role and benefits of cognition and perception in medical imaging" />
  <meta property="og:title" content="The role and benefits of cognition and perception in medical imaging" />
  <meta property="twitter:title" content="The role and benefits of cognition and perception in medical imaging" />
  <meta name="dc.date" content="2020-04-27" />
  <meta name="citation_publication_date" content="2020-04-27" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="Melissa Treviño" />
  <meta name="citation_author_institution" content="National Cancer Institute" />
  <meta name="citation_author" content="Todd S. Horowitz" />
  <meta name="citation_author_institution" content="National Cancer Institute" />
  <meta name="citation_author_orcid" content="0000-0001-5571-6266" />
  <link rel="canonical" href="https://thorowitz.github.io/ThinkTankClinicians/" />
  <meta property="og:url" content="https://thorowitz.github.io/ThinkTankClinicians/" />
  <meta property="twitter:url" content="https://thorowitz.github.io/ThinkTankClinicians/" />
  <meta name="citation_fulltext_html_url" content="https://thorowitz.github.io/ThinkTankClinicians/" />
  <meta name="citation_pdf_url" content="https://thorowitz.github.io/ThinkTankClinicians/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://thorowitz.github.io/ThinkTankClinicians/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://thorowitz.github.io/ThinkTankClinicians/v/cd55dc7265a6d1b3f233a9898c9080503471bdd1/" />
  <meta name="manubot_html_url_versioned" content="https://thorowitz.github.io/ThinkTankClinicians/v/cd55dc7265a6d1b3f233a9898c9080503471bdd1/" />
  <meta name="manubot_pdf_url_versioned" content="https://thorowitz.github.io/ThinkTankClinicians/v/cd55dc7265a6d1b3f233a9898c9080503471bdd1/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
</head>
<body>
<header id="title-block-header">
<h1 class="title">The role and benefits of cognition and perception in medical imaging</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://thorowitz.github.io/ThinkTankClinicians/v/cd55dc7265a6d1b3f233a9898c9080503471bdd1/">permalink</a>)
was automatically generated
from <a href="https://github.com/thorowitz/ThinkTankClinicians/tree/cd55dc7265a6d1b3f233a9898c9080503471bdd1">thorowitz/ThinkTankClinicians@cd55dc7</a>
on April 27, 2020.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Melissa Treviño</strong><br><br>
<small>
National Cancer Institute
</small></p></li>
<li><p><strong>Todd S. Horowitz</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-5571-6266">0000-0001-5571-6266</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/thorowitz">thorowitz</a><br>
<small>
National Cancer Institute
</small></p></li>
</ul>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<h2 id="introduction">INTRODUCTION</h2>
<p>In an era of unprecedented technological advances across the field of medical imaging, it is critically important to understand the cognitive and perceptual functioning of the “human in the loop,” the clinicians
who make the final decisions on detection, diagnosis, and treatment.
However, research on the cognitive and perceptual processes underlying clinician performance is chronically understudied.
In September 2019, the National Cancer Institute (NCI) convened the “Cognition and Medical Image Perception Think Tank” in order to advance research on medical image perception<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and cognition.
The Think Tank brought radiologists and pathologists together with researchers working in medical image perception and adjacent fields of cognition and perception, along with representatives from interested federal government agencies (including NCI, National Institute of Biomedical Imaging and Bioengineering, U.S. Food and Drug Administration, U.S. Department of Homeland Security) to address the Think Tank’s key objectives (see Table <a href="#tbl:Objectives">1</a>) through panel discussions, constructive discourse, idea generation, and problem-solving.
Panel discussions were guided by critical questions generated by the participants themselves in advance of the meeting.
Here, we report on the Think Tank’s deliberations and highlight opportunities to expand the research in medical image perception and cognition.</p>
<div id="tbl:Objectives" class="tablenos">
<table>
<caption><span>Table 1:</span> Think Tank Objectives
</caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Objectives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. Identify research gaps and critical unsolved problems in pathology and radiology, from the perspective of clinicians.</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. Discuss ways to address these clinically-informed questions through cognitive and perceptual research.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3. Identify barriers that hinder collaborations between researchers and clinicians and identify potential solutions.</td>
</tr>
<tr class="even">
<td style="text-align: left;">4. Identify and discuss ways to elevate psychology’s profile within the medical image community and broader communities.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5. Identify future goals and identify strategies to evaluate progress.</td>
</tr>
</tbody>
</table>
</div>
<h2 id="identifying-research-gaps">Identifying research gaps</h2>
<p>Detection and diagnosis rely on clinicians<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> searching for abnormalities in medical images.
Across the many ways to acquire images (from light microscopy to magnetic resonance) and present them (e.g., via glass slides or computer workstations), clinicians are confronted with similar perceptual and cognitive challenges.
Clinicians are tasked with bringing to bear a vast amount of medical knowledge, together with contextual information about the patient (e.g., referring physician’s information, prior report, prior medical history, genomics information) in order to interpret highly complex and variable images quickly and accurately.
This is a highly challenging endeavor.
Clinicians face many difficulties, from information overload to repeated interruptions to clinician burnout, that in turn are closely associated with health care quality, patient safety, and financial burdens on practices <span class="citation" data-cites="L4wXOjRX PwkCa9cq 12Yo2Wqzk">(<span class="citeproc-not-found" data-reference-id="12Yo2Wqzk"><strong>???</strong></span>; Panagioti et al., <a href="#ref-L4wXOjRX" role="doc-biblioref">2018</a>; Shanafelt et al., <a href="#ref-PwkCa9cq" role="doc-biblioref">2017</a>)</span>.
Even under ideal circumstances, human observers are bound to make mistakes.
Errors, both false positives and false negatives, are a reality in both radiology <span class="citation" data-cites="16PQVInWA bcJHwopH 12WLsUQZz">(Berlin, <a href="#ref-16PQVInWA" role="doc-biblioref">2007</a>; Haider et al., <a href="#ref-bcJHwopH" role="doc-biblioref">2016</a>; Sivaraman et al., <a href="#ref-12WLsUQZz" role="doc-biblioref">2015</a>)</span> and pathology practice <span class="citation" data-cites="kYdmZkOd">(Raab et al., <a href="#ref-kYdmZkOd" role="doc-biblioref">2005</a>)</span>.
The majority of diagnostic errors in radiology can be traced to perceptual and cognitive factors (Berlin &amp; Berlin, 1995; Smith, 1967).
The same is probably true in pathology, though there is much less research in this area (Raab et al., 2005).
Improving the accuracy of diagnosis requires an understanding of the perceptual and cognitive mechanisms underlying the performance of clinicians.
Additionally, cognitive and perceptual principles and approaches should be applied to address issues concerning clinicians’ work environment and well-being.</p>
<p>What research should we encourage in order to improve clinicians’ diagnostic accuracy, work environment, and well-being? The first challenge for the Think Tank participants was to identify the research gaps and critical unsolved problems in pathology and radiology, from the perspective of clinicians.
The primary challenges identified by the clinicians were information overload and integrating large amounts of information from various sources.</p>
<p>For example, the transition from the analog to digital eras has meant a qualitative change in the nature of the radiological problem.
A radiologist scrutinizing a single chest X-ray for a lung nodule is trying to extract a target with a very low signal:noise ratio (SNR) from a single image.
The same radiologist reading a chest CT is searching for a target with a fairly high SNR in a scan comprising thousands of images (slices).
In addition, the radiologist must now incorporate into her decision information from outside sources, such as electronic health records and genetic panels, that may not have been available in the past.
Furthermore, the decisions that clinicians have to make have gotten more complex as precision medicine has advanced.
A pathologist now might have to indicate not just whether something is a tumor or not, but if the tumor is hot or cold, likely to be responsive or non-responsive.
The cognitive capacity of the clinician, in contrast, has not changed, and the time pressure has only gotten worse.
What are the effects of information overload on medical decision making and decision quality? Are there technical solutions or decision-making aids or strategies that could be used to efficiently integrate complex information? For example, psychologically distancing oneself from information has been shown to improve non-medical decision-making (Fukukura et al., 2013).
What is the applicability of decision strategies to real world practice? The cognitive and perceptual challenges of the clinicians’ role, and the implications for practice, are poorly understood at present.</p>
<p>Task shifting was another topic identified by the Think Tank participants.
Interruptions and distractions from a variety of sources (e.g., texts, email, pager, colleagues, telephone) may lead clinicians to miss or fail to report important findings.
Another form of task shifting is when clinicians move from case to case, different organs, while using various image modalities.
There is no research on whether task shifting in medical imaging creates adverse sequential consequences and/or how to mitigate these effects.</p>
<p>As one might expect from the above descriptions, the workload for clinicians has increased, and physical and mental fatigue of clinicians are at unprecedented levels, contributing to both perceptual and interpretive errors.
Fatigue can manifest as attention errors, such as when a clinician scrolls too fast through multi-slice or volumetric images, which may give the false impression that the clinician has sufficiently viewed the case.
Additional errors can result from lack of focus, getting easily distracted, and/or failing to record what is perceived.
These errors caused by physical and mental fatigue become more apparent at the end of the day.
Multiple studies have reported a decrease in detection accuracy due to fatigue (for a review, see Waite et al., 2017) but translational research needs to be conducted to mitigate fatigue effects in real world practice.</p>
<p>Interpretative errors can occur from a variety of sources.
For radiologists, several categories of tumors can be difficult to interpret, such as when there is a subtle gradient (i.e., when it is difficult to notice subtle changes or new lesions) from benign to malignant tumors, malignant to benign tumors, and when benign tumors mimic malignant tumors.
Additionally, it is also often difficult to interpret or connect two dissonant findings (e.g., adrenal nodule with a lung mass) and the clinician ends up failing to link findings and report a complete picture.
Research should focus on understanding the perceptual and cognitive underpinnings of these type of cases to help mitigate interpretation difficulty.</p>
<p>Artificial intelligence (AI) tools are often proposed as a solution to the challenges facing clinicians.
However, there is a mismatch between what clinicians need from AI and how AI is typically developed.
AI solutions are often pitched as “outperforming” the clinician, implying that AI systems are on the cusp of replacing the clinician (Mukherjee, 2017), or at least serving as an equivalent reader (McKinney et al., 2020).
This stems from an incomplete picture of the clinician’s job.
A better approach would be to develop AI as a tool to automate the data reduction process, extracting the information that will aid the clinician’s decision process.
For example, when reading pap smears, cytotechnologists can sign off on cases that are unequivocally negative, leaving the cytopathologists to focus only on cases with potential abnormalities.
AI could usefully fulfill this sort of role, and potentially automate quality assurance (QA) procedures.
A useful framework is the “diagnostic cockpit of the future”, described by Krupinski et al.
(2019) as a set of tools to “aggregate, organize, and simplify medical imaging results and patient-centric clinical data.” This metaphor underscores the role of AI in helping to winnow the information available to the clinician and present only the most clinically relevant information in the clearest way possible.
In order to accomplish these goals, AI should be developed within a broad interdisciplinary context.
Clinical, perceptual, and cognitive perspectives are all needed in the development process, rather than treated as an afterthought.</p>
<h2 id="addressing-clinical-questions-through-perceptual-research">Addressing clinical questions through perceptual research</h2>
<p>There’s an old science joke that goes something like this: A dairy farmer is looking for ways to increase the output of his cows, as cheaply as possible.
He consults an agronomist, who recommends changes to the feedstock and new equipment which will require major investments. He turns to a biologist, who suggests hormone treatments that will be cheaper, but still involve an outlay of more money than he wants to spend.
Finally, he turns to a physicist, who promises a free solution. He eagerly asks her to explain her idea.
She begins, “First, assume a spherical cow with radius <em>r</em> and mass <em>m</em>, uniformly emitting milk in all directions…”</p>
<p>To many clinicians, perceptual research on medical image interpretation can sometimes seem like the equivalent of a spherical cow emitting milk in all directions.
Perceptual studies typically abstract away from the specificity and messiness of the clinical reading context in order to gain experimental control.
Complex stimuli are simplified, narrative reports are replaced with binary responses, clinical history is absent, and the life-and-death stakes of the clinic are removed.
Consider Wolfe and Horowitz’s work on the effects of prevalence <span class="citation" data-cites="f6dC7TPP">(Wolfe et al., <a href="#ref-f6dC7TPP" role="doc-biblioref">2007</a>)</span>, in which amateur observers drawn from the Cambridge, MA community searching for the letter “T” concealed among arrays of “L”s are meant to have some relevance to radiologists searching for cancerous lesions in mammograms or lung CTs.
Traditional medical image perception research may skew closer to the clinical experience, using experienced professional readers and real cases.
Even so, the consequences for a missed target or unnecessary callback are not the same.
Furthermore, in perceptual research each trial in a given experimental condition is assumed to be equivalent to other trials (because stimuli are typically randomly and algorithmically generated), to the clinician, each case is unique, leading to a reluctance to generalize.
All of these factors may lead to a certain skepticism in the clinician community about the value of perception research, especially in the face of the difficulties raised in the <em>Identifying Research Gaps</em> section.</p>
<p>There is a trend in medical image perception studies where the researcher follows a “Reverse Translation” model to assess clinical problems.
This is where a researcher observes a problem in the clinic that resembles an area of perception research they are doing in the lab or has familiarity with.
The researcher will then develop lab versions of the problem to study the basic perceptual and cognitive science principles of the problem.
These studies will sometimes use observer models or undergraduate students as they are more efficient to use lab studies as clinicians time is limited.
After many iterations of working out the basic science and once the researcher has a good working hypothesis, they will then go back in the clinical setting to test their hypothesis.
A major issue with this model is that the problems that are being assessed are not the critical issues that clinicians actually want answers to.
We propose researchers adopt a “Reverse Translation Phase 2” model, where researchers investigate problems and that are important to the clinician and then follow the same “Reverse Translation” procedure.</p>
<p>Within the “Reverse Translation Phase 2” model, there are key assumptions that allow for the translation of principles studied and derived from lab studies to the clinical setting even when clinicians or medical images are not being utilized.
First, clinicians and non-clinicians have the same visual systems and perceptual and cognitive faculties that allow us to process and interpret stimuli.
Second, artificial tasks and stimuli capture the key elements of the clinical tasks and stimuli. Going back to the work on prevalence effects, studying the effect of low prevalence on radiologists’ performance with a reader study would take years to complete and would put a substantial burden on clinicians.
Medical image perception studies have replicated the prevalence effect in the lab setting using non-clinician readers and non-medical image stimuli <span class="citation" data-cites="FO7nrJY6">(Wolfe et al., <a href="#ref-FO7nrJY6" role="doc-biblioref">2005</a>)</span>, demonstrated low prevalence influences non-clinician and clinician readers’ response criteria <span class="citation" data-cites="bpr3toJK 1781dDiit CUXUOHx3">(Evans et al., <a href="#ref-1781dDiit" role="doc-biblioref">2011</a>, <a href="#ref-bpr3toJK" role="doc-biblioref">2013</a>; Wolfe &amp; Van Wert, <a href="#ref-CUXUOHx3" role="doc-biblioref">2010</a>)</span>, and have proposed potential solutions to mitigate prevalence effects <span class="citation" data-cites="YFvzsEu2 GGN55MAr hlvO0EOy zLGy7VUt">(Lau &amp; Huang, <a href="#ref-YFvzsEu2" role="doc-biblioref">2010</a>; Navalpakkam et al., <a href="#ref-GGN55MAr" role="doc-biblioref">2009</a>; Schwark et al., <a href="#ref-hlvO0EOy" role="doc-biblioref">2012</a>; Wolfe et al., <a href="#ref-zLGy7VUt" role="doc-biblioref">2013</a>)</span>.</p>
<h2 id="enabling-collaborative-transdisciplinary-research">Enabling collaborative transdisciplinary research</h2>
<p>Successful collaborations between clinicians and perception researchers<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> are essential to address the dynamic challenges that clinicians face.
The study of medical image perception is an inherently trans-disciplinary enterprise, often requiring collaborations between clinicians, medical physicists, computer scientists, biomedical informatics engineers, and psychologists.
Historically, medical image perception research was led by clinicians, notably William Tuddenham and Harold Kundel <span class="citation" data-cites="gdp1ZapN twyIxNLh">(Kundel, <a href="#ref-gdp1ZapN" role="doc-biblioref">2006</a>; Tuddenham, <a href="#ref-twyIxNLh" role="doc-biblioref">1962</a>)</span>, who championed applying principles from psychology and other disciplines to advance medical image research <span class="citation" data-cites="MVYtm8Xo">(Tuddenham, <a href="#ref-MVYtm8Xo" role="doc-biblioref">1969</a>)</span>.
These collaborations were easier to initiate in an era when perceptual psychologists (such as Elizabeth Krupinski at Emory University, or Philip Judy at Brigham and Women’s Hospital) were embedded in radiology departments.
These researchers were intimately familiar with the problems and perspectives of clinicians, and could also easily find collaborators.
Unfortunately, this model has fallen out of favor.
Today, multiple barriers hinder collaborations between perception researchers and clinicians (see Table <a href="#tbl:barriers">2</a>).
Here, we expand on the challenges and potential solutions that were discussed.</p>
<p>The main constraint on successful collaborations is the limited time clinicians have to be active researchers and/or participate in reader studies.
Collaborations should be designed to respect the clinician’s schedule, and projects should be developed around common interests of both parties.
Resources should be available for clinicians through incentives and grant mechanisms.
Incentives for clinicians participating in reader studies are either nonexistent or not beneficial for the clinician.
Think Tank participants proposed a number of possible solutions.
An important step would be to provide incentives continuing medical education (CME) credit and/or CME in Risk Management for participating in research.
In order to facilitate CME credit, an educational module should be created for participants.
Possible objectives for this educational module could include education on classic visual search and interpretive errors (e.g., prevalence effects, satisfaction of search errors, satisfaction of report errors, cognitive biases) and fundamental perceptual or cognitive concepts relating to clinical practice (e.g., perceptual attributes of expertise, development of global processing, attentional mechanisms).
A more ambitious suggestion is to create joint funding opportunities with the Agency for Healthcare Research &amp; Quality (AHRQ), NCI’s Healthcare Delivery Research Program and Behavioral Research Programs, and the National Institute of Biomedical Imaging and Bioengineering (NIBIB) to support collaborative research funding, protected time for clinicians committed to research, and/or mentoring junior research scientists.</p>
<p>Organizing “pop-up” perception laboratories at clinician conferences to recruit clinicians in reader studies has been successful in recent years <span class="citation" data-cites="gcYDYJ6P">(Toomey et al., <a href="#ref-gcYDYJ6P" role="doc-biblioref">2019</a>)</span>, but sustaining these efforts will require partnering with national and regional medical conferences (e.g.
American Society for Clinical Pathology (ASCP), Radiological Society of North America (RSNA), Society of Nuclear Medicine and Molecular Imaging, The Association for Medical Ultrasound), university medical centers, NCI designated cancer centers, and the American College of Radiology, to make medical image perception research a priority, and to financially sustain perception laboratories.
Perception laboratories at conferences could also be sustained through NIH R24 or R25 grant mechanisms.</p>
<p>Collaboration often develops serendipitously, and serendipity depends on proximity.
For perception researchers who are not embedded within medical centers, opportunities to network or promote research though invited talks are limited.
One solution would be to create a match-making resource to identify perception researchers, clinicians, conferences, private practices, and medical departments that are open to collaborative research.
Contributors would indicate their areas of expertise and of interest, and the type of contribution they were interested in providing, such as participating in reader studies, inviting researchers to give talks at their institutions, providing image datasets, generating research ideas and providing feedback, or becoming investigators.
Another idea is to bring perception science to the clinicians.
While the primary purpose of a pop-up lab like the NCI Perception Lab at RSNA is to recruit clinicians as participants, these endeavors can also provide opportunities for exposing clinicians to perceptual research and sparking conversations between researchers and clinicians.
These outreach opportunities could be expanded, perhaps by providing workshops on perceptual science at a variety of clinical meetings, where perceptual scientists could explain their research and exchange ideas with clinicians.</p>
<p>Accessing medical image datasets can be a challenge for perception researchers.
Curating large image datasets is often time-consuming for the clinician and requires financial resources to undertake and sustain.
Sharing images across institutions is difficult due to liability issues.
Even access to image sets from large, government-funded trials can be arduous and depend on the preferences of the original PIs.
Furthermore, access may be only for restricted uses, such as specific research projects, making it difficult to develop clinical tools.
These problems could be addressed by developing templates for peer-to-peer research collaboration and sharing agreement.</p>
<p>There are also existing image repositories (e.g., NCI’s The Cancer Imaging Archive, TCIA).
These repositories may avoid the access difficulties associated with clinical trial image sets, but they often lack needed clinical context, appropriate annotations, and an efficient interface for navigating and searching for relevant images.
One possible solution would be to emulate the Crowds Cure Cancer project, which was created in 2017 to address the lack of annotations in NCI’s Cancer Imaging Archive.
Crowds Cure Cancer recruited radiologists attending RSNA to identify lesions, lesion characteristics, and provide details regarding image quality.
This professional crowdsourcing model could be a template for annotating other large medical image repositories.
Involving perception scientists in the design of the project could help to ensure that variables important to perception studies were coded as well.</p>
<p>Another factor is the rise in recent years of AI approaches to medical image interpretation.
If machines are going to be finding the lesions and counting the abnormal cells, then understanding how the human perceptual system interprets medical images is a waste of time.
Even for clinicians who are skeptical about the potential of AI to replace them (or the timeline) may find that AI projects compete with perception research for their limited research time.</p>
<div id="tbl:barriers" class="tablenos">
<table>
<caption><span>Table 2:</span> Barriers to Transdisciplinary Research
</caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Barriers that Hinder Collaborations Between Researchers and Clinicians.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. Time Pressures for Clinicians.<br> - Access to clinicians is limited in terms of collaborations and participation in reader studies.<br> - Incentives (i.e., CEM/RME Credit) should be provided to clinicians.</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. Lack of Networking Among Disciplines.<br> - Increase the probability of serendipitous collaborations by creating a “matchmaking” resource.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3. Limited Access to Image Datasets</td>
</tr>
<tr class="even">
<td style="text-align: left;">4. What is the relevance of human perception in the face of AI?</td>
</tr>
</tbody>
</table>
</div>
<h2 id="elevating-the-profile-of-medical-image-perception-research">Elevating the profile of medical image perception research</h2>
<p>Elevating the profile of medical image perception research within the broader medical and scientific communities (e.g., government agencies, industry, advocacy groups, journal editors, review panels, study sections) is essential to ensure a sustainable future for this important research endeavor.
Here we identify key essential elements for achieving this goal (see Table <a href="#tbl:profile">3</a>).</p>
<p>Creating a network of invested stakeholders (e.g., clinicians, academia, biomedical informatics, government and regulatory agencies, medical centers, industry, conferences) is critical to support an awareness program promoting education, collaboration, and research.
Clinician advocates are needed to lend visibility and credibility to perception research, and to highlight its importance to the medical community.
This is important not just to facilitate the research itself, but also to encourage adoption and implementation of research-based solutions to clinician challenges.
Potential models for this network include the National Collaborative on Childhood Obesity Research (NCCOR) and the Alliance for Digital Pathology (ADP).
NCCOR is a partnership between federal government agencies (NIH, USDA, and CDC) and the non-profit Robert Wood Johnson Foundation.
NCCOR provides infrastructure and resources to promote collaborative research, and supports an outreach program to educate the community on successful collaborations that are fighting childhood obesity.
The Alliance for Digital Pathology is a regulatory science initiative that brings together clinicians, researchers, government, and industry to identity key aims to advance digital pathology and provide an infrastructure for collaborative projects.</p>
<p>Outreach efforts at conferences are needed to engage and inform the communities.
Symposiums should be held at clinician conferences, such as the ASCP and RSNA, to educate clinicians on how the science of cognition and perception can inform their work, and to highlight research findings that have produced positive changes in clinical practice.
Perception researchers should create a model “reading room of the future” at conferences and invite clinicians to different workstations that promote research outcomes.
Symposiums and workshops on medical image perception should be held at cognition and perception conferences (e.g., Psychonomic Society, Vision Sciences Society).
As a model, consider the outreach efforts conducted by The International Society for Optics and Photonics (SPIE) to educate researchers on the clinician’s perspective and challenges, such as organizing demonstrations of clinicians interpreting images to allow researchers to learn how clinicians read.</p>
<p>Clinicians should be given training in fundamental concepts of cognition and perception, as they pertain to diagnostic performance in clinical practice.
This training should be included in the noninterpretive skills section of the American Board of Radiology (ABR) Core and Certifying examination.
Similar to the educational module for CME credit (see <em>Enabling Collaborative Transdisciplinary Research</em> section), fundamental topics should include: classification of visual search errors, development of global processing, attentional mechanisms related to clinical practice, and classic perceptual and interpretive errors.
It would also be a good idea to revive the practice of providing training for NIH study sections tasked with reviewing medical image perception research proposals.</p>
<p>Publishing cognition and perception medical image research in medical journals, particularly special issues journals (e.g., human observer performance issues in Journal of Medical Imaging), ensures credibility and visibility among clinicians.
However, publishing in main radiology journals is uneven.
Research papers, tutorial reviews, and editorials should be placed in prominent journals read by radiologists, pathologists, and other clinicians.
Special issues could be commissioned.
Potential journals to target include: <em>Journal of Medical Imaging</em>, <em>Archives of Medicine</em>, <em>Modern Pathology</em>, <em>Journal of Pathology Informatics</em>.</p>
<div id="tbl:profile" class="tablenos">
<table>
<caption><span>Table 3:</span> Medical Image Cognition and Perception’s Profile
</caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Ways to Elevate Medical Image Cognition and Perception’s Profile Within the Medical Image Community</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. Create a network of invested stakeholders (e.g., clinicians, academia, biomedical informatics, government and regulatory agencies, medical centers, industry) to support an awareness program promoting education, collaboration, and research.</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. Outreach and Roadshows.<br> - Educate clinicians about cognition and perception.<br> - Educate cognition and perception researchers about the clinicians perspective.<br> - Add outreach to the perception lab model.<br> - Reading room of the future</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3. Education Trainings.<br> - Trainings on cognitive and perceptual fundamentals as “noninterpretive skills”.<br> - Trainings for study sections.</td>
</tr>
<tr class="even">
<td style="text-align: left;">4. Publish research in special issues in medical journals to ensure credibility and visibility among clinicians.</td>
</tr>
</tbody>
</table>
</div>
<h2 id="future-goals-and-strategies-to-evaluate-progress">Future goals and strategies to evaluate progress</h2>
<p>The overall goal in advancing medical image perception research is to improve patient care by reducing diagnostic errors, improving machine interfaces, and mitigating clinicians’ challenges.
How will we know if this initiative is bearing fruit? Table <a href="#tbl:future-goals">4</a> lists intermediate goals, metrics, and strategies to evaluate and achieve progress.</p>
<p>We can track the success of outreach efforts by looking at metrics such as the number of funding announcements or the number of new principle investigators recruited into the field.
We can also track the impact of medical image perception research on clinical practices (e.g., industry modifications to workstations and AI, decrease in malpractice lawsuits), clinical outcomes, such as reduction in errors, reduction in time clinicians spend per case, and reduction in clinician burn-out rates, and outreach efforts (e.g., grants funded, workshops and perception pop-up labs held at conferences).
Ultimately, these clinical outcomes should be modeled to measure the overall improvement in potential lives saved and/or quality of adjusted live years gained.
The baseline for the trajectory of the field using the proposed metrics should begin with 2014, the year that NCI’s Vision Science Problems in Medical Imaging Workshop was held.
We can then compare progress to a counterfactual trajectory, based on extrapolating prior trends, and assess what is needed to change and/or further change the trajectories’ slopes.</p>
<p>A match-making resource (see <em>Enabling Collaborative Transdisciplinary Research</em> section) will be an instrumental tool for the medical image and cognitive science communities to connect and network for possible collaborative research in whichever capacity they choose.
Since, the Think Tank convened, NCI has created a website &lt;&lt;<a href="https://cancercontrol.cancer.gov/brp/bbpsb/cognitive-changes/perception.html" class="uri">https://cancercontrol.cancer.gov/brp/bbpsb/cognitive-changes/perception.html</a> &gt;&gt; where contributors are asked to list their name, title, affiliation, email, area of expertise or interest, and brief description of a proposed project or potential research contribution.
Content is only visible to consenting contributors.</p>
<p>Engaging the broader and higher order cognitive science community, such as human judgement, decision making, and financial decision making, can offer a unique set of skills, expertise, and perspectives for addressing problems faced by clinicians (see <em>Identifying Research Gaps</em> section).
For example, clinicians are often confronted with classic decision-making problems, (i.e., integrating abundant and various forms of information and making multiple decisions) which have been extensively researched but not in the context of medical imaging.
These communities could offer insight to further advance medical imaging research.
Symposiums and workshops on medical imaging and clinicians’ issues should be held at broader cognitive science conferences to engage widespread audiences (i.e., Society for Mathematical Psychology, the Society of Medical Decision Making).</p>
<div id="tbl:future-goals" class="tablenos">
<table>
<caption><span>Table 4:</span> Future Goals
</caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Future Goals and Strategies to Evaluate Progress</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. Metrics.<br> - Track the number of funding announcements, grants submitted, grants funded, workshops and pop-up labs held at conferences, new principle investigators in the field.<br> - Track clinical practice changes.<br> - Industry modifications to workstations that have resulted from cognition and perception research.<br> - Reduction in diagnostic errors.<br> - Quantify the trajectory starting in 2014, what is the counterfactual?<br> - What can we do to change the slope?</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. NCI’s networking website.<br> - <a href="https://cancercontrol.cancer.gov/brp/bbpsb/cognitive-changes/perception.html" class="uri">https://cancercontrol.cancer.gov/brp/bbpsb/cognitive-changes/perception.html</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;">3. Engage the broader cognitive science community.</td>
</tr>
</tbody>
</table>
</div>
<h2 id="summary-of-think-tank-deliberations">Summary of think tank deliberations</h2>
<p>NCI’s “Cognition and Medical Image Perception Thank Tank” brought together clinicians, perception researchers, and representatives from government agencies and the medical image community to deliberate and identify courses of action to advance medical image perception research.
Attendees pinpointed key challenges facing clinicians that perception research could address using an updated reverse translational model.
Barriers that have hindered successful trans-disciplinary collaborations between clinicians and perception researchers were discussed and potential solutions were purposed.
To elevate the field’s profile within the medical image community, ways to promote perception education, collaboration, and research were identified.
Finally, concrete goals and strategies were established to evaluate the progress of medical image perception research in terms of improving clinical practice and clinical outcomes; and in terms of expanding and advancing the field.
Advancing medical image perception research requires active participation from clinicians, perception researchers, and the medical image community.
Together these fields can improve patient care by addressing the many and diverse challenges facing clinicians.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-16PQVInWA">
<p>Berlin, L. (2007). Accuracy of Diagnostic Procedures: Has It Improved Over the Past Five Decades? <em>American Journal of Roentgenology</em>, <em>188</em>(5), 1173–1178. <a href="https://doi.org/10.2214/ajr.06.1270">https://doi.org/10.2214/ajr.06.1270</a></p>
</div>
<div id="ref-bpr3toJK">
<p>Evans, K. K., Birdwell, R. L., &amp; Wolfe, J. M. (2013). If You Don’t Find It Often, You Often Don’t Find It: Why Some Cancers Are Missed in Breast Cancer Screening. <em>PLoS ONE</em>, <em>8</em>(5), e64366. <a href="https://doi.org/10.1371/journal.pone.0064366">https://doi.org/10.1371/journal.pone.0064366</a></p>
</div>
<div id="ref-1781dDiit">
<p>Evans, K. K., Tambouret, R. H., Evered, A., Wilbur, D. C., &amp; Wolfe, J. M. (2011). Prevalence of Abnormalities Influences Cytologists’ Error Rates in Screening for Cervical Cancer. <em>Archives of Pathology &amp; Laboratory Medicine</em>, <em>135</em>(12), 1557–1560. <a href="https://doi.org/10.5858/arpa.2010-0739-oa">https://doi.org/10.5858/arpa.2010-0739-oa</a></p>
</div>
<div id="ref-bcJHwopH">
<p>Haider, M. A., Yao, X., Loblaw, A., &amp; Finelli, A. (2016). Multiparametric Magnetic Resonance Imaging in the Diagnosis of Prostate Cancer: A Systematic Review. <em>Clinical Oncology</em>, <em>28</em>(9), 550–567. <a href="https://doi.org/10.1016/j.clon.2016.05.003">https://doi.org/10.1016/j.clon.2016.05.003</a></p>
</div>
<div id="ref-gdp1ZapN">
<p>Kundel, H. L. (2006). History of Research in Medical Image Perception. <em>Journal of the American College of Radiology</em>, <em>3</em>(6), 402–408. <a href="https://doi.org/10.1016/j.jacr.2006.02.023">https://doi.org/10.1016/j.jacr.2006.02.023</a></p>
</div>
<div id="ref-YFvzsEu2">
<p>Lau, J. S.-H., &amp; Huang, L. (2010). The prevalence effect is determined by past experience, not future prospects. <em>Vision Research</em>, <em>50</em>(15), 1469–1474. <a href="https://doi.org/10.1016/j.visres.2010.04.020">https://doi.org/10.1016/j.visres.2010.04.020</a></p>
</div>
<div id="ref-GGN55MAr">
<p>Navalpakkam, V., Koch, C., &amp; Perona, P. (2009). Homo economicus in visual search. <em>Journal of Vision</em>, <em>9</em>(1), 31–31. <a href="https://doi.org/10.1167/9.1.31">https://doi.org/10.1167/9.1.31</a></p>
</div>
<div id="ref-L4wXOjRX">
<p>Panagioti, M., Geraghty, K., Johnson, J., Zhou, A., Panagopoulou, E., Chew-Graham, C., Peters, D., Hodkinson, A., Riley, R., &amp; Esmail, A. (2018). Association Between Physician Burnout and Patient Safety, Professionalism, and Patient Satisfaction. <em>JAMA Internal Medicine</em>, <em>178</em>(10), 1317. <a href="https://doi.org/10.1001/jamainternmed.2018.3713">https://doi.org/10.1001/jamainternmed.2018.3713</a></p>
</div>
<div id="ref-kYdmZkOd">
<p>Raab, S. S., Grzybicki, D. M., Janosky, J. E., Zarbo, R. J., Meier, F. A., Jensen, C., &amp; Geyer, S. J. (2005). Clinical impact and frequency of anatomic pathology errors in cancer diagnoses. <em>Cancer</em>, <em>104</em>(10), 2205–2213. <a href="https://doi.org/10.1002/cncr.21431">https://doi.org/10.1002/cncr.21431</a></p>
</div>
<div id="ref-hlvO0EOy">
<p>Schwark, J., Sandry, J., MacDonald, J., &amp; Dolgov, I. (2012). False feedback increases detection of low-prevalence targets in visual search. <em>Attention, Perception, &amp; Psychophysics</em>, <em>74</em>(8), 1583–1589. <a href="https://doi.org/10.3758/s13414-012-0354-4">https://doi.org/10.3758/s13414-012-0354-4</a></p>
</div>
<div id="ref-PwkCa9cq">
<p>Shanafelt, T., Goh, J., &amp; Sinsky, C. (2017). The Business Case for Investing in Physician Well-being. <em>JAMA Internal Medicine</em>, <em>177</em>(12), 1826. <a href="https://doi.org/10.1001/jamainternmed.2017.4340">https://doi.org/10.1001/jamainternmed.2017.4340</a></p>
</div>
<div id="ref-12WLsUQZz">
<p>Sivaraman, A., Sanchez-Salas, R., Ahmed, H. U., Barret, E., Cathala, N., Mombet, A., Uriburu Pizarro, F., Carneiro, A., Doizi, S., Galiano, M., Rozet, F., Prapotnich, D., &amp; Cathelineau, X. (2015). Clinical utility of transperineal template-guided mapping biopsy of the prostate after negative magnetic resonance imaging−guided transrectal biopsy. <em>Urologic Oncology: Seminars and Original Investigations</em>, <em>33</em>(7), 329.e7–329.e11. <a href="https://doi.org/10.1016/j.urolonc.2015.04.005">https://doi.org/10.1016/j.urolonc.2015.04.005</a></p>
</div>
<div id="ref-gcYDYJ6P">
<p>Toomey, R. J., McEntee, M. F., &amp; Rainford, L. A. (2019). The pop-up research centre – Challenges and opportunities. <em>Radiography</em>, <em>25</em>, S19–S24. <a href="https://doi.org/10.1016/j.radi.2019.05.009">https://doi.org/10.1016/j.radi.2019.05.009</a></p>
</div>
<div id="ref-twyIxNLh">
<p>Tuddenham, W. J. (1962). Visual Search, Image Organization, and Reader Error in Roentgen Diagnosis. <em>Radiology</em>, <em>78</em>(5), 694–704. <a href="https://doi.org/10.1148/78.5.694">https://doi.org/10.1148/78.5.694</a></p>
</div>
<div id="ref-MVYtm8Xo">
<p>Tuddenham, W. J. (1969). Roentgen image perception–a personal survey of the problem. <em>Radiologic Clinics of North America</em>, <em>7</em>(3), 499–501. <a href="https://www.ncbi.nlm.nih.gov/pubmed/5382261">https://www.ncbi.nlm.nih.gov/pubmed/5382261</a></p>
</div>
<div id="ref-zLGy7VUt">
<p>Wolfe, J. M., Brunelli, D. N., Rubinstein, J., &amp; Horowitz, T. S. (2013). Prevalence effects in newly trained airport checkpoint screeners: Trained observers miss rare targets, too. <em>Journal of Vision</em>, <em>13</em>(3), 33–33. <a href="https://doi.org/10.1167/13.3.33">https://doi.org/10.1167/13.3.33</a></p>
</div>
<div id="ref-FO7nrJY6">
<p>Wolfe, J. M., Horowitz, T. S., &amp; Kenner, N. M. (2005). Rare items often missed in visual searches. <em>Nature</em>, <em>435</em>(7041), 439–440. <a href="https://doi.org/10.1038/435439a">https://doi.org/10.1038/435439a</a></p>
</div>
<div id="ref-f6dC7TPP">
<p>Wolfe, J. M., Horowitz, T. S., Van Wert, M. J., Kenner, N. M., Place, S. S., &amp; Kibbi, N. (2007). Low target prevalence is a stubborn source of errors in visual search tasks. <em>Journal of Experimental Psychology: General</em>, <em>136</em>(4), 623–638. <a href="https://doi.org/10.1037/0096-3445.136.4.623">https://doi.org/10.1037/0096-3445.136.4.623</a></p>
</div>
<div id="ref-CUXUOHx3">
<p>Wolfe, J. M., &amp; Van Wert, M. J. (2010). Varying Target Prevalence Reveals Two Dissociable Decision Criteria in Visual Search. <em>Current Biology</em>, <em>20</em>(2), 121–124. <a href="https://doi.org/10.1016/j.cub.2009.11.066">https://doi.org/10.1016/j.cub.2009.11.066</a></p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>We use the term “medical image perception” to cover a wide range of imaging techniques from images of individual cells used in pathology to whole-body radiological images, from glass slides to 3D computer renderings.
In addition to detection and diagnosis, medical imaging can also be used to guide surgical interventions.
We also extend to term beyond artificially created images; a dermatologist examining your skin, for example, is engaged in a medical image perception task.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Here we will use the word “clinicians” to refer to anyone tasked with reading a medical image. The typical clinician in this sense will be a radiologist or pathologist, but the term should be understood to include many other specialties such as nuclear medicine or dermatology, as well as non-specialists who read images as part of their practice.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>We are using “perception research” as a shorthand for all the research fields that can contribute to an understanding of the cognitive and perceptual context of medical image perception. This should be understood to encompass cognitive psychology, vision science, cognitive neuroscience, and so forth.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!-- default theme -->

<style>
    /* import google fonts */
    @import url("https://fonts.googleapis.com/css?family=Libre+Baskerville:400,600,700");
    @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

    /* -------------------------------------------------- */
    /* global */
    /* -------------------------------------------------- */

    /* all elements */
    * {
        /* force sans-serif font unless specified otherwise */
        font-family: "Libre Baskerville", "Georgia", serif;

        /* prevent text inflation on some mobile browsers */
        -webkit-text-size-adjust: none !important;
        -moz-text-size-adjust: none !important;
        -o-text-size-adjust: none !important;
        text-size-adjust: none !important;
    }

    @media only screen {
        /* "page" element */
        body {
            position: relative;
            box-sizing: border-box;
            font-size: 12pt;
            line-height: 1.5;
            max-width: 8.5in;
            margin: 20px auto;
            padding: 40px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* "page" element */
        body {
            padding: 20px;
            margin: 0;
            border-radius: 0;
            border: none;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
            background: none;
        }
    }

    /* -------------------------------------------------- */
    /* headings */
    /* -------------------------------------------------- */

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 20px 0;
        padding: 0;
        font-weight: bold;
    }

    /* biggest heading */
    h1 {
        margin: 40px 0;
        text-align: center;
    }

    /* second biggest heading */
    h2 {
        margin-top: 30px;
        padding-bottom: 5px;
        border-bottom: solid 1px #bdbdbd;
    }

    /* -------------------------------------------------- */
    /* manuscript header */
    /* -------------------------------------------------- */

    /* manuscript title */
    header > h1 {
        margin: 0;
    }

    /* manuscript title caption text (ie "automatically generated on") */
    header + p {
        text-align: center;
        margin-top: 10px;
    }

    /* -------------------------------------------------- */
    /* text elements */
    /* -------------------------------------------------- */

    /* links */
    a {
        color: #2196f3;
        overflow-wrap: break-word;
    }

    /* normal links (not empty, not button link, not syntax highlighting link) */
    a:not(:empty):not(.button):not(.sourceLine) {
        padding-left: 1px;
        padding-right: 1px;
    }

    /* superscripts and subscripts */
    sub,
    sup {
        /* prevent from affecting line height */
        line-height: 0;
    }

    /* unordered and ordered lists*/
    ul,
    ol {
        padding-left: 20px;
    }

    /* class for styling text semibold */
    .semibold {
        font-weight: 600;
    }

    /* class for styling elements horizontally left aligned */
    .left {
        display: block;
        text-align: left;
        margin-left: auto;
        margin-right: 0;
        justify-content: left;
    }

    /* class for styling elements horizontally centered */
    .center {
        display: block;
        text-align: center;
        margin-left: auto;
        margin-right: auto;
        justify-content: center;
    }

    /* class for styling elements horizontally right aligned */
    .right {
        display: block;
        text-align: right;
        margin-left: 0;
        margin-right: auto;
        justify-content: right;
    }

    /* -------------------------------------------------- */
    /* section elements */
    /* -------------------------------------------------- */

    /* horizontal divider line */
    hr {
        border: none;
        height: 1px;
        background: #bdbdbd;
    }

    /* paragraphs, horizontal dividers, figures, tables, code */
    p,
    hr,
    figure,
    table,
    pre {
        /* treat all as "paragraphs", with consistent vertical margins */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* figures */
    /* -------------------------------------------------- */

    /* figure */
    figure {
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure caption */
    figcaption {
        padding: 0;
        padding-top: 10px;
    }

    /* figure image element */
    figure img {
        max-width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure auto-number */
    img + figcaption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* tables */
    /* -------------------------------------------------- */

    /* table */
    table {
        border-collapse: collapse;
        border-spacing: 0;
        width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* table cells */
    th,
    td {
        border: solid 1px #bdbdbd;
        padding: 10px;
        /* squash table if too wide for page by forcing line breaks */
        overflow-wrap: break-word;
        word-break: break-word;
    }

    /* header row and even rows */
    th,
    tr:nth-child(2n) {
        background-color: #fafafa;
    }

    /* odd rows */
    tr:nth-child(2n + 1) {
        background-color: #ffffff;
    }

    /* table caption */
    caption {
        text-align: left;
        padding: 0;
        padding-bottom: 10px;
    }

    /* table auto-number */
    table > caption > span:first-of-type,
    div.table_wrapper > table > caption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* code */
    /* -------------------------------------------------- */

    /* multi-line code block */
    pre {
        padding: 10px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
        break-inside: avoid;
        text-align: left;
    }

    /* inline code, ie code within normal text */
    :not(pre) > code {
        padding: 0 4px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
    }

    /* code text */
    /* apply all children, to reach syntax highlighting sub-elements */
    code,
    code * {
        /* force monospace font */
        font-family: "Source Code Pro", "Courier New", monospace;
    }

    /* -------------------------------------------------- */
    /* quotes */
    /* -------------------------------------------------- */

    /* quoted text */
    blockquote {
        margin: 0;
        padding: 0;
        border-left: 4px solid #bdbdbd;
        padding-left: 16px;
        break-inside: avoid;
    }

    /* -------------------------------------------------- */
    /* banners */
    /* -------------------------------------------------- */

    /* info banners */
    .banner {
        box-sizing: border-box;
        display: block;
        position: relative;
        width: 100%;
        margin-top: 20px;
        margin-bottom: 20px;
        padding: 20px;
        text-align: center;
    }

    /* paragraph in banner */
    .banner > p {
        margin: 0;
    }

    /* -------------------------------------------------- */
    /* highlight colors */
    /* -------------------------------------------------- */

    .white {
        background: #ffffff;
    }
    .lightgrey {
        background: #eeeeee;
    }
    .grey {
        background: #757575;
    }
    .darkgrey {
        background: #424242;
    }
    .black {
        background: #000000;
    }
    .lightred {
        background: #ffcdd2;
    }
    .lightyellow {
        background: #ffecb3;
    }
    .lightgreen {
        background: #dcedc8;
    }
    .lightblue {
        background: #e3f2fd;
    }
    .lightpurple {
        background: #f3e5f5;
    }
    .red {
        background: #f44336;
    }
    .orange {
        background: #ff9800;
    }
    .yellow {
        background: #ffeb3b;
    }
    .green {
        background: #4caf50;
    }
    .blue {
        background: #2196f3;
    }
    .purple {
        background: #9c27b0;
    }
    .white,
    .lightgrey,
    .lightred,
    .lightyellow,
    .lightgreen,
    .lightblue,
    .lightpurple,
    .orange,
    .yellow,
    .white a,
    .lightgrey a,
    .lightred a,
    .lightyellow a,
    .lightgreen a,
    .lightblue a,
    .lightpurple a,
    .orange a,
    .yellow a {
        color: #000000;
    }
    .grey,
    .darkgrey,
    .black,
    .red,
    .green,
    .blue,
    .purple,
    .grey a,
    .darkgrey a,
    .black a,
    .red a,
    .green a,
    .blue a,
    .purple a {
        color: #ffffff;
    }

    /* -------------------------------------------------- */
    /* buttons */
    /* -------------------------------------------------- */

    /* class for styling links like buttons */
    .button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        margin: 5px;
        padding: 10px 20px;
        font-size: 0.75em;
        font-weight: 600;
        text-transform: uppercase;
        text-decoration: none;
        letter-spacing: 1px;
        background: none;
        color: #2196f3;
        border: solid 1px #bdbdbd;
        border-radius: 5px;
    }

    /* buttons when hovered */
    .button:hover:not([disabled]),
    .icon_button:hover:not([disabled]) {
        cursor: pointer;
        background: #f5f5f5;
    }

    /* buttons when disabled */
    .button[disabled],
    .icon_button[disabled] {
        opacity: 0.35;
        pointer-events: none;
    }

    /* class for styling buttons containg only single icon */
    .icon_button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        text-decoration: none;
        margin: 0;
        padding: 0;
        background: none;
        border-radius: 5px;
        border: none;
        width: 20px;
        height: 20px;
        min-width: 20px;
        min-height: 20px;
    }

    /* icon button inner svg image */
    .icon_button > svg {
        height: 16px;
    }

    /* -------------------------------------------------- */
    /* icons */
    /* -------------------------------------------------- */

    /* class for styling icons inline with text */
    .inline_icon {
        height: 1em;
        position: relative;
        top: 0.125em;
    }

    /* -------------------------------------------------- */
    /* print control */
    /* -------------------------------------------------- */

    @media print {
        @page {
            /* suggested printing margin */
            margin: 0.5in;
        }

        /* document and "page" elements */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
        }

        /* "page" element */
        body {
            font-size: 11pt !important;
            line-height: 1.35;
        }

        /* all headings */
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            margin: 15px 0;
        }

        /* heading 1 */
        h1 {
            font-size: 1.75em;
        }

        /* heading 2 */
        h2 {
            font-size: 1.25em;
            margin-top: 0;
        }

        /* heading 3 */
        h3 {
            font-size: 1.10em;
        }

        /* figures and tables */
        figure, table {
            font-size: 0.85em;
        }

        /* table cells */
        th,
        td {
            padding: 5px;
        }

        /* shrink font awesome icons */
        i.fas,
        i.fab,
        i.far,
        i.fal {
            transform: scale(0.85);
        }

        /* decrease banner margins */
        .banner {
            margin-top: 15px;
            margin-bottom: 15px;
            padding: 15px;
        }

        /* class for centering an element vertically on its own page */
        .page_center {
            margin: auto;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            vertical-align: middle;
            break-before: page;
            break-after: page;
        }

        /* always insert a page break before the element */
        .page_break_before {
            break-before: page;
        }

        /* always insert a page break after the element */
        .page_break_after {
            break-after: page;
        }

        /* avoid page break before the element */
        .page_break_before_avoid {
            break-before: avoid;
        }

        /* avoid page break after the element */
        .page_break_after_avoid {
            break-after: avoid;
        }

        /* avoid page break inside the element */
        .page_break_inside_avoid {
            break-inside: avoid;
        }
    }

    /* -------------------------------------------------- */
    /* override pandoc css quirks */
    /* -------------------------------------------------- */

    .sourceCode {
        /* prevent unsightly overflow in wide code blocks */
        overflow: auto !important;
    }

    div.sourceCode {
        /* prevent background fill on top-most code block  container */
        background: none !important;
    }

    .sourceCode * {
        /* force consistent line spacing */
        line-height: 1.5 !important;
    }

    div.sourceCode {
        /* style code block margins same as <pre> element */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* tablenos */
    /* -------------------------------------------------- */

    /* tablenos wrapper */
    .tablenos {
        /* show scrollbar on tables if necessary to prevent overflow */
        width: 100%;
        margin: 20px 0;
    }

    .tablenos > table {
        /* move margins from table to table_wrapper to allow margin collapsing */
        margin: 0;
    }

    @media only screen {
        /* tablenos wrapper */
        .tablenos {
            /* show scrollbar on tables if necessary to prevent overflow */
            overflow-x: auto !important;
        }

        .tablenos th,
        .tablenos td {
            overflow-wrap: unset !important;
            word-break: unset !important;
        }

        /* table in wrapper */
        .tablenos table,
        .tablenos table * {
            /* don't break table words */
            overflow-wrap: normal !important;
        }
    }

    /* -------------------------------------------------- */
    /* mathjax */
    /* -------------------------------------------------- */

    /* mathjax containers */
    .math.display > span:not(.MathJax_Preview) {
        /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
        display: flex !important;
        overflow-x: auto !important;
        overflow-y: hidden !important;
        justify-content: center;
        align-items: center;
        margin: 0 !important;
    }

    /* right click menu */
    .MathJax_Menu {
        border-radius: 5px !important;
        border: solid 1px #bdbdbd !important;
        box-shadow: none !important;
    }

    /* equation auto-number */
    span[id^="eq:"] > span.math.display + span {
        font-weight: 600;
    }

    /* equation */
    span[id^="eq:"] > span.math.display > span {
        /* nudge to make room for equation auto-number and anchor */
        margin-right: 60px !important;
    }

    /* -------------------------------------------------- */
    /* anchors plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anchor button */
        .anchor {
            opacity: 0;
            margin-left: 5px;
        }

        /* anchor buttons within <h2>'s */
        h2 .anchor {
            margin-left: 10px;
        }

        /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
        *:hover > .anchor,
        .anchor:hover,
        .anchor:focus {
            opacity: 1;
        }

        /* anchor button when hovered */
        .anchor:hover {
            cursor: pointer;
        }
    }

    /* always show anchor button on devices with no mouse/hover ability */
    @media (hover: none) {
        .anchor {
            opacity: 1;
        }
    }

    /* always hide anchor button on print */
    @media only print {
        .anchor {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* accordion plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* accordion arrow button */
        .accordion_arrow {
            margin-right: 10px;
        }

        /* arrow icon when <h2> data-collapsed attribute true */
        h2[data-collapsed="true"] > .accordion_arrow > svg {
            transform: rotate(-90deg);
        }

        /* all elements (except <h2>'s) when data-collapsed attribute true */
        *:not(h2)[data-collapsed="true"] {
            display: none;
        }

        /* accordion arrow button when hovered and <h2>'s when hovered */
        .accordion_arrow:hover,
        h2[data-collapsed="true"]:hover,
        h2[data-collapsed="false"]:hover {
            cursor: pointer;
        }
    }

    /* always hide accordion arrow button on print */
    @media only print {
        .accordion_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* tooltips plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* tooltip container */
        #tooltip {
            position: absolute;
            width: 50%;
            min-width: 240px;
            max-width: 75%;
            z-index: 1;
        }

        /* tooltip content */
        #tooltip_content {
            margin-bottom: 5px;
            padding: 20px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
            overflow-wrap: break-word;
        }

        /* tooltip copy of paragraphs and figures */
        #tooltip_content > p,
        #tooltip_content > figure {
            margin: 0;
            max-height: 320px;
            overflow-y: auto;
        }

        /* tooltip copy of <img> */
        #tooltip_content > figure > img {
            max-height: 260px;
        }

        /* navigation bar */
        #tooltip_nav_bar {
            margin-top: 10px;
            text-align: center;
        }

        /* navigation bar previous/next buton */
        #tooltip_nav_bar > .icon_button {
            position: relative;
            top: 3px;
        }

        /* navigation bar previous button */
        #tooltip_nav_bar > .icon_button:first-of-type {
            margin-right: 5px;
        }

        /* navigation bar next button */
        #tooltip_nav_bar > .icon_button:last-of-type {
            margin-left: 5px;
        }
    }

    /* always hide tooltip on print */
    @media only print {
        #tooltip {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* jump to first plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* jump button */
        .jump_arrow {
            position: relative;
            top: 0.125em;
            margin-right: 5px;
        }
    }

    /* always hide jump button on print */
    @media only print {
        .jump_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* link highlight plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anything with data-highlighted attribute true */
        [data-highlighted="true"] {
            background: #ffeb3b;
        }

        /* anything with data-selected attribute true */
        [data-selected="true"] {
            background: #ff8a65 !important;
        }

        /* animation definition for glow */
        @keyframes highlight_glow {
            0% {
                background: none;
            }
            10% {
                background: #bbdefb;
            }
            100% {
                background: none;
            }
        }

        /* anything with data-glow attribute true */
        [data-glow="true"] {
            animation: highlight_glow 2s;
        }
    }

    /* -------------------------------------------------- */
    /* table of contents plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* toc panel */
        #toc_panel {
            box-sizing: border-box;
            position: fixed;
            top: 0;
            left: 0;
            background: #ffffff;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            z-index: 2;
        }

        /* toc panel when closed */
        #toc_panel[data-open="false"] {
            min-width: 60px;
            width: 60px;
            height: 60px;
            border-right: solid 1px #bdbdbd;
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc panel when open */
        #toc_panel[data-open="true"] {
            min-width: 260px;
            max-width: 480px;
            /* keep panel edge consistent distance away from "page" edge */
            width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
            bottom: 0;
            border-right: solid 1px #bdbdbd;
        }

        /* toc panel header */
        #toc_header {
            box-sizing: border-box;
            display: flex;
            flex-direction: row;
            align-items: center;
            height: 60px;
            margin: 0;
            padding: 20px;
        }

        /* toc panel header when hovered */
        #toc_header:hover {
            cursor: pointer;
        }

        /* toc panel header when panel open */
        #toc_panel[data-open="true"] > #toc_header {
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc open/close header button */
        #toc_button {
            margin-right: 20px;
        }

        /* hide toc list and header text when closed */
        #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
        #toc_panel[data-open="false"] > #toc_list {
            display: none;
        }

        /* toc list of entries */
        #toc_list {
            box-sizing: border-box;
            width: 100%;
            padding: 20px;
            position: absolute;
            top: calc(60px + 1px);
            bottom: 0;
            overflow: auto;
        }

        /* toc entry, link to section in document */
        .toc_link {
            display: block;
            padding: 5px;
            position: relative;
            font-weight: 600;
            text-decoration: none;
        }

        /* toc entry when hovered or when "viewed" */
        .toc_link:hover,
        .toc_link[data-viewing="true"] {
            background: #f5f5f5;
        }

        /* toc entry, level 1 indentation */
        .toc_link[data-level="1"] {
            margin-left: 0;
        }

        /* toc entry, level 2 indentation */
        .toc_link[data-level="2"] {
            margin-left: 20px;
        }

        /* toc entry, level 3 indentation */
        .toc_link[data-level="3"] {
            margin-left: 40px;
        }

        /* toc entry, level 4 indentation */
        .toc_link[data-level="4"] {
            margin-left: 60px;
        }

        /* toc entry bullets */
        #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
            position: absolute;
            left: -15px;
            top: -1px;
            font-size: 1.5em;
        }

        /* toc entry, level 2 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
            content: "\2022";
        }

        /* toc entry, level 3 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
            content: "\25AB";
        }

        /* toc entry, level 4 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
            content: "-";
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* push <body> ("page") element down to make room for toc icon */
        .toc_body_nudge {
            padding-top: 60px;
        }

        /* toc icon when panel closed and not hovered */
        #toc_panel[data-open="false"]:not(:hover) {
            background: rgba(255, 255, 255, 0.75);
        }
    }

    /* always hide toc panel on print */
    @media only print {
        #toc_panel {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* lightbox plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* regular <img> in document when hovered */
        .lightbox_document_img:hover {
            cursor: pointer;
        }

        .body_no_scroll {
            overflow: hidden !important;
        }

        /* screen overlay */
        #lightbox_overlay {
            display: flex;
            flex-direction: column;
            position: fixed;
            left: 0;
            top: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.75);
            z-index: 3;
        }

        /* middle area containing lightbox image */
        #lightbox_image_container {
            flex-grow: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            position: relative;
            padding: 20px;
        }

        /* bottom area containing caption */
        #lightbox_bottom_container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100px;
            min-height: 100px;
            max-height: 100px;
            background: rgba(0, 0, 0, 0.5);
        }

        /* image number info text box */
        #lightbox_number_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            left: 2px;
            top: 0;
            z-index: 4;
        }

        /* zoom info text box */
        #lightbox_zoom_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            right: 2px;
            top: 0;
            z-index: 4;
        }

        /* copy of image caption */
        #lightbox_caption {
            box-sizing: border-box;
            display: inline-block;
            width: 100%;
            max-height: 100%;
            padding: 10px 0;
            text-align: center;
            overflow-y: auto;
            color: #ffffff;
        }

        /* navigation previous/next button */
        .lightbox_button {
            width: 100px;
            height: 100%;
            min-width: 100px;
            min-height: 100%;
            color: #ffffff;
        }

        /* navigation previous/next button when hovered */
        .lightbox_button:hover {
            background: none !important;
        }

        /* navigation button icon */
        .lightbox_button > svg {
            height: 25px;
        }

        /* figure auto-number */
        #lightbox_caption > span:first-of-type {
            font-weight: bold;
            margin-right: 5px;
        }

        /* lightbox image when hovered */
        #lightbox_img:hover {
            cursor: grab;
        }

        /* lightbox image when grabbed */
        #lightbox_img:active {
            cursor: grabbing;
        }
    }

    /* when on screen < 480px wide */
    @media only screen and (max-width: 480px) {
        /* make navigation buttons skinnier on small screens to make more room for caption text */
        .lightbox_button {
            width: 50px;
            min-width: 50px;
        }
    }

    /* always hide lightbox on print */
    @media only print {
        #lightbox_overlay {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* hypothesis (annotations) plugin */
    /* -------------------------------------------------- */

    /* side panel */
    .annotator-frame {
        width: 280px !important;
        z-index: 0 !important;
    }

    /* match highlight color to rest of theme */
    .annotator-highlights-always-on .annotator-hl {
        background-color: #ffeb3b !important;
    }

    /* match focused color to rest of theme */
    .annotator-hl.annotator-hl-focused {
        background-color: #ff8a65 !important;
    }

    /* match bucket bar color to rest of theme */
    .annotator-bucket-bar {
        background: #f5f5f5 !important;
    }

    /* always hide toolbar and tooltip on print */
    @media only print {
        .annotator-frame {
            display: none !important;
        }

        hypothesis-adder {
            display: none !important;
        }
    }
</style>
<!-- anchors plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds an anchor next to each of a certain type
        // of element that provides a human-readable url to that specific
        // item/position in the document (eg "manuscript.html#abstract"). It
        // also makes it such that scrolling out of view of a target removes
        // its identifier from the url.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'anchors';

        // default plugin options
        const options = {
            // which types of elements to add anchors next to, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3, [id^="fig:"], [id^="tbl:"], [id^="eq:"]',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // add anchor to each element of specified types
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements)
                addAnchor(element);

            // attach scroll listener to window
            window.addEventListener('scroll', onScroll);
        }

        // when window is scrolled
        function onScroll() {
            // if url has hash and user has scrolled out of view of hash
            // target, remove hash from url
            const tolerance = 100;
            const target = getHashTarget();
            if (target) {
                if (
                    target.getBoundingClientRect().top >
                        window.innerHeight + tolerance ||
                    target.getBoundingClientRect().bottom < 0 - tolerance
                )
                    history.pushState(null, null, ' ');
            }
        }

        // add anchor to element
        function addAnchor(element) {
            let addTo; // element to add anchor button to

            // if figure or table, modify withId and addTo to get expected
            // elements
            if (element.id.indexOf('fig:') === 0) {
                addTo = element.querySelector('figcaption');
            } else if (element.id.indexOf('tbl:') === 0) {
                addTo = element.querySelector('caption');
            } else if (element.id.indexOf('eq:') === 0) {
                addTo = element.querySelector('.eqnos-number');
            }

            addTo = addTo || element;
            const id = element.id || null;

            // do not add anchor if element doesn't have assigned id.
            // id is generated by pandoc and is assumed to be unique and
            // human-readable
            if (!id)
                return;

            // create anchor button
            const anchor = document.createElement('a');
            anchor.innerHTML = document.querySelector('.icon_link').innerHTML;
            anchor.title = 'Link to this part of the document';
            anchor.classList.add('icon_button', 'anchor');
            anchor.dataset.ignore = 'true';
            anchor.href = '#' + id;
            addTo.appendChild(anchor);
        }

        // get element that is target of link or url hash
        function getHashTarget() {
            const hash = window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- link icon -->

<template class="icon_link">
    <!-- modified from: https://fontawesome.com/icons/link -->
    <svg width="16" height="16" viewBox="0 0 512 512">
        <path
            fill="currentColor"
            d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
        ></path>
    </svg>
</template>
<!-- accordion plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows sections of content under <h2> headings
        // to be collapsible.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'accordion';

        // default plugin options
        const options = {
            // whether to always start expanded ('false'), always start
            // collapsed ('true'), or start collapsed when screen small ('auto')
            startCollapsed: 'auto',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <h2> heading
            const headings = document.querySelectorAll('h2');
            for (const heading of headings) {
                addArrow(heading);

                // start expanded/collapsed based on option
                if (
                    options.startCollapsed === 'true' ||
                    (options.startCollapsed === 'auto' && isSmallScreen())
                )
                    collapseHeading(heading);
                else
                    expandHeading(heading);
            }

            // attach hash change listener to window
            window.addEventListener('hashchange', onHashChange);
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                goToElement(target);
        }

        // add arrow to heading
        function addArrow(heading) {
            // add arrow button
            const arrow = document.createElement('button');
            arrow.innerHTML = document.querySelector(
                '.icon_angle_down'
            ).innerHTML;
            arrow.classList.add('icon_button', 'accordion_arrow');
            heading.insertBefore(arrow, heading.firstChild);

            // attach click listener to heading and button
            heading.addEventListener('click', onHeadingClick);
            arrow.addEventListener('click', onArrowClick);
        }

        // determine if on mobile-like device with small screen
        function isSmallScreen() {
            return Math.min(window.innerWidth, window.innerHeight) < 480;
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get element that is target of hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // when <h2> heading is clicked
        function onHeadingClick(event) {
            // only collapse if <h2> itself is target of click (eg, user did
            // not click on anchor within <h2>)
            if (event.target === this)
                toggleCollapse(this);
        }

        // when arrow button is clicked
        function onArrowClick() {
            toggleCollapse(this.parentNode);
        }

        // collapse section if expanded, expand if collapsed
        function toggleCollapse(heading) {
            if (heading.dataset.collapsed === 'false')
                collapseHeading(heading);
            else
                expandHeading(heading);
        }

        // elements to exclude from collapse, such as table of contents panel,
        // hypothesis panel, etc
        const exclude = '#toc_panel, div.annotator-frame, #lightbox_overlay';

        // collapse section
        function collapseHeading(heading) {
            heading.setAttribute('data-collapsed', 'true');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'true');
        }

        // expand section
        function expandHeading(heading) {
            heading.setAttribute('data-collapsed', 'false');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'false');
        }

        // get list of elements between this <h2> and next <h2> or <h1>
        // ("children" of the <h2> section)
        function getChildren(heading) {
            return nextUntil(heading, 'h2, h1', exclude);
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get list of elements after a start element up to element matching
        // query
        function nextUntil(element, query, exclude) {
            const elements = [];
            while (element = element.nextElementSibling, element) {
                if (element.matches(query))
                    break;
                if (!element.matches(exclude))
                    elements.push(element);
            }
            return elements;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
    <!-- modified from: https://fontawesome.com/icons/angle-down -->
    <svg width="16" height="16" viewBox="0 0 448 512">
        <path
            fill="currentColor"
            d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
        ></path>
    </svg>
</template>
<!-- tooltips plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when the user hovers or
        // focuses a link to a citation or figure, a tooltip appears with a
        // preview of the reference content, along with arrows to navigate
        // between instances of the same reference in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tooltips';

        // default plugin options
        const options = {
            // whether user must click off to close tooltip instead of just
            // un-hovering
            clickClose: 'false',
            // delay (in ms) between opening and closing tooltip
            delay: '100',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach hover and focus listeners to link
                link.addEventListener('mouseover', onLinkHover);
                link.addEventListener('mouseleave', onLinkUnhover);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('touchend', onLinkTouch);
            }

            // attach mouse, key, and resize listeners to window
            window.addEventListener('mousedown', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('keyup', onKeyUp);
            window.addEventListener('resize', onResize);
        }

        // when link is hovered
        function onLinkHover() {
            // function to open tooltip
            const delayOpenTooltip = function() {
                openTooltip(this);
            }.bind(this);

            // run open function after delay
            this.openTooltipTimer = window.setTimeout(
                delayOpenTooltip,
                options.delay
            );
        }

        // when mouse leaves link
        function onLinkUnhover() {
            // cancel opening tooltip
            window.clearTimeout(this.openTooltipTimer);

            // don't close on unhover if option specifies
            if (options.clickClose === 'true')
                return;

            // function to close tooltip
            const delayCloseTooltip = function() {
                // if tooltip open and if mouse isn't over tooltip, close
                const tooltip = document.getElementById('tooltip');
                if (tooltip && !tooltip.matches(':hover'))
                    closeTooltip();
            };

            // run close function after delay
            this.closeTooltipTimer = window.setTimeout(
                delayCloseTooltip,
                options.delay
            );
        }

        // when link is focused (tabbed to)
        function onLinkFocus(event) {
            openTooltip(this);
        }

        // when link is touched on touch screen
        function onLinkTouch(event) {
            // attempt to force hover state on first tap always, and trigger
            // regular link click (and navigation) on second tap
            if (event.target === document.activeElement)
                event.target.click();
            else {
                document.activeElement.blur();
                event.target.focus();
            }
            if (event.cancelable)
                event.preventDefault();
            event.stopPropagation();
            return false;
        }

        // when mouse is clicked anywhere in window
        function onClick(event) {
            closeTooltip();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'tooltip_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'tooltip_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeTooltip();
                    break;
            }
        }

        // when window is resized or zoomed
        function onResize() {
            closeTooltip();
        }

        // get all links of types we wish to handle
        function getLinks() {
            const queries = [];
            // exclude buttons, anchor links, toc links, etc
            const exclude =
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            queries.push('a[href^="#ref-"]' + exclude); // citation links
            queries.push('a[href^="#fig:"]' + exclude); // figure links
            const query = queries.join(', ');
            return document.querySelectorAll(query);
        }

        // get links with same target, get index of link in set, get total
        // same links
        function getSameLinks(link) {
            const sameLinks = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    sameLinks.push(otherLink);
            }

            return {
                elements: sameLinks,
                index: sameLinks.indexOf(link),
                total: sameLinks.length
            };
        }

        // open tooltip
        function openTooltip(link) {
            // delete tooltip if it exists, start fresh
            closeTooltip();

            // make tooltip element
            const tooltip = makeTooltip(link);

            // if source couldn't be found and tooltip not made, exit
            if (!tooltip)
                return;

            // make navbar elements
            const navBar = makeNavBar(link);
            if (navBar)
                tooltip.firstElementChild.appendChild(navBar);

            // attach tooltip to page
            document.body.appendChild(tooltip);

            // position tooltip
            const position = function() {
                positionTooltip(link);
            };
            position();

            // if tooltip contains images, position again after they've loaded
            const imgs = tooltip.querySelectorAll('img');
            for (const img of imgs)
                img.addEventListener('load', position);
        }

        // close (delete) tooltip
        function closeTooltip() {
            const tooltip = document.getElementById('tooltip');
            if (tooltip)
                tooltip.remove();
        }

        // make tooltip
        function makeTooltip(link) {
            // get target element that link points to
            const source = getSource(link);

            // if source can't be found, exit
            if (!source)
                return;

            // create new tooltip
            const tooltip = document.createElement('div');
            tooltip.id = 'tooltip';
            const tooltipContent = document.createElement('div');
            tooltipContent.id = 'tooltip_content';
            tooltip.appendChild(tooltipContent);

            // make copy of source node and put in tooltip
            const sourceCopy = makeCopy(source);
            tooltipContent.appendChild(sourceCopy);

            // attach mouse event listeners
            tooltip.addEventListener('click', onTooltipClick);
            tooltip.addEventListener('mousedown', onTooltipClick);
            tooltip.addEventListener('touchstart', onTooltipClick);
            tooltip.addEventListener('mouseleave', onTooltipUnhover);

            // (for interaction with lightbox plugin)
            // transfer click on tooltip copied img to original img
            const sourceImg = source.querySelector('img');
            const sourceCopyImg = sourceCopy.querySelector('img');
            if (sourceImg && sourceCopyImg) {
                const clickImg = function() {
                    sourceImg.click();
                    closeTooltip();
                };
                sourceCopyImg.addEventListener('click', clickImg);
            }

            return tooltip;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // when tooltip is clicked
        function onTooltipClick(event) {
            // when user clicks on tooltip, stop click from transferring
            // outside of tooltip (eg, click off to close tooltip, or eg click
            // off to unhighlight same refs)
            event.stopPropagation();
        }

        // when tooltip is unhovered
        function onTooltipUnhover(event) {
            if (options.clickClose === 'true')
                return;

            // make sure new mouse/touch/focus no longer over tooltip or any
            // element within it
            const tooltip = document.getElementById('tooltip');
            if (!tooltip)
                return;
            if (this.contains(event.relatedTarget))
                return;

            closeTooltip();
        }

        // make nav bar to go betwen prev/next instances of same reference
        function makeNavBar(link) {
            // find other links to the same source
            const sameLinks = getSameLinks(link);

            // don't show nav bar when singular reference
            if (sameLinks.total <= 1)
                return;

            // find prev/next links with same target
            const prevLink = getPrevLink(link, sameLinks);
            const nextLink = getNextLink(link, sameLinks);

            // create nav bar
            const navBar = document.createElement('div');
            navBar.id = 'tooltip_nav_bar';
            const text = sameLinks.index + 1 + ' of ' + sameLinks.total;

            // create nav bar prev/next buttons
            const prevButton = document.createElement('button');
            const nextButton = document.createElement('button');
            prevButton.id = 'tooltip_prev_button';
            nextButton.id = 'tooltip_next_button';
            prevButton.title =
                'Jump to the previous occurence of this item in the document [←]';
            nextButton.title =
                'Jump to the next occurence of this item in the document [→]';
            prevButton.classList.add('icon_button');
            nextButton.classList.add('icon_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;
            navBar.appendChild(prevButton);
            navBar.appendChild(document.createTextNode(text));
            navBar.appendChild(nextButton);

            // attach click listeners to buttons
            prevButton.addEventListener('click', function() {
                onPrevNextClick(link, prevLink);
            });
            nextButton.addEventListener('click', function() {
                onPrevNextClick(link, nextLink);
            });

            return navBar;
        }

        // get previous link with same target
        function getPrevLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if < 1
            let index;
            if (sameLinks.index - 1 >= 0)
                index = sameLinks.index - 1;
            else
                index = sameLinks.total - 1;
            return sameLinks.elements[index];
        }

        // get next link with same target
        function getNextLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if > total
            let index;
            if (sameLinks.index + 1 <= sameLinks.total - 1)
                index = sameLinks.index + 1;
            else
                index = 0;
            return sameLinks.elements[index];
        }

        // get element that is target of link or url hash
        function getSource(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if ref or figure, modify target to get expected element
            if (id.indexOf('ref-') === 0)
                target = target.querySelector('p');
            else if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');

            return target;
        }

        // when prev/next arrow button is clicked
        function onPrevNextClick(link, prevNextLink) {
            if (link && prevNextLink)
                goToElement(prevNextLink, window.innerHeight * 0.5);
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // determine position to place tooltip based on link position in
        // viewport and tooltip size
        function positionTooltip(link, left, top) {
            const tooltipElement = document.getElementById('tooltip');
            if (!tooltipElement)
                return;

            // get convenient vars for position/dimensions of
            // link/tooltip/page/view
            link = getRectInPage(link);
            const tooltip = getRectInPage(tooltipElement);
            const view = getRectInPage();

            // horizontal positioning
            if (left)
                // use explicit value
                left = left;
            else if (link.left + tooltip.width < view.right)
                // fit tooltip to right of link
                left = link.left;
            else if (link.right - tooltip.width > view.left)
                // fit tooltip to left of link
                left = link.right - tooltip.width;
            // center tooltip in view
            else
                left = (view.right - view.left) / 2 - tooltip.width / 2;

            // vertical positioning
            if (top)
                // use explicit value
                top = top;
            else if (link.top - tooltip.height > view.top)
                // fit tooltip above link
                top = link.top - tooltip.height;
            else if (link.bottom + tooltip.height < view.bottom)
                // fit tooltip below link
                top = link.bottom;
            else {
                // center tooltip in view
                top = view.top + view.height / 2 - tooltip.height / 2;
                // nudge off of link to left/right if possible
                if (link.right + tooltip.width < view.right)
                    left = link.right;
                else if (link.left - tooltip.width > view.left)
                    left = link.left - tooltip.width;
            }

            tooltipElement.style.left = left + 'px';
            tooltipElement.style.top = top + 'px';
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get position of element relative to page
        function getRectInPage(element) {
            const rect = getRectInView(element);
            const body = getRectInView(document.body);

            const newRect = {};
            newRect.left = rect.left - body.left;
            newRect.top = rect.top - body.top;
            newRect.right = rect.right - body.left;
            newRect.bottom = rect.bottom - body.top;
            newRect.width = rect.width;
            newRect.height = rect.height;

            return newRect;
        }

        // (for interaction with accordion plugin)
        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // (for interaction with accordion plugin)
        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- jump to first plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds a button next to each reference entry,
        // figure, and table that jumps the page to the first occurrence of a
        // link to that item in the manuscript.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'jumpToFirst';

        // default plugin options
        const options = {
            // whether to add buttons next to reference entries
            references: 'true',
            // whether to add buttons next to figures
            figures: 'true',
            // whether to add buttons next to tables
            tables: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            if (options.references !== 'false')
                makeReferenceButtons();
            if (options.figures !== 'false')
                makeFigureButtons();
            if (options.tables !== 'false')
                makeTableButtons();
        }

        // when jump button clicked
        function onButtonClick() {
            const first = getFirstOccurrence(this.dataset.id);
            if (!first)
                return;

            // update url hash so navigating "back" in history will return
            // user to jump button
            window.location.hash = this.dataset.id;
            // scroll to link
            window.setTimeout(function() {
                goToElement(first, window.innerHeight * 0.5);
            }, 0);
        }

        // get first occurence of link to item in document
        function getFirstOccurrence(id) {
            let query = 'a';
            query += '[href="#' + id + '"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelector(query);
        }

        // add button next to each reference entry
        function makeReferenceButtons() {
            const references = document.querySelectorAll('div[id^="ref-"]');
            for (const reference of references) {
                // get reference id and element to add button to
                const id = reference.id;
                const container = reference.firstElementChild;
                const first = getFirstOccurrence(id);

                // if can't find link to reference, ignore
                if (!first)
                    continue;

                // make jump button
                let button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this reference in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.innerHTML = button.outerHTML + container.innerHTML;
                button = container.firstElementChild;
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeFigureButtons() {
            const figures = document.querySelectorAll('[id^="fig:"]');
            for (const figure of figures) {
                // get figure id and element to add button to
                const id = figure.id;
                const container = figure.querySelector('figcaption') || figure;
                const first = getFirstOccurrence(id);

                // if can't find link to figure, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this figure in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeTableButtons() {
            const tables = document.querySelectorAll('[id^="tbl:"]');
            for (const table of tables) {
                // get ref id and element to add button to
                const id = table.id;
                const container = table.querySelector('caption') || table;
                const first = getFirstOccurrence(id);

                // if can't find link to table, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this table in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
    <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
    <svg width="16" height="16" viewBox="0 0 320 512">
        <path
            fill="currentColor"
            d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
        ></path>
    </svg>
</template>
<!-- link highlight plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user hovers or
        // focuses a link, other links that have the same target will be
        // highlighted. It also makes it such that when clicking a link, the
        // target of the link (eg reference, figure, table) is briefly
        // highlighted.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'linkHighlight';

        // default plugin options
        const options = {
            // whether to also highlight links that go to external urls
            externalLinks: 'false',
            // whether user must click off to unhighlight instead of just
            // un-hovering
            clickUnhighlight: 'false',
            // whether to also highlight links that are unique
            highlightUnique: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach mouse and focus listeners to link
                link.addEventListener('mouseenter', onLinkFocus);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('mouseleave', onLinkUnhover);
            }

            // attach click and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('hashchange', onHashChange);

            // run hash change on window load in case user has navigated
            // directly to hash
            onHashChange();
        }

        // when link is focused (tabbed to) or hovered
        function onLinkFocus() {
            highlight(this);
        }

        // when link is unhovered
        function onLinkUnhover() {
            if (options.clickUnhighlight !== 'true')
                unhighlightAll();
        }

        // when the mouse is clicked anywhere in window
        function onClick(event) {
            unhighlightAll();
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                glowElement(target);
        }

        // get element that is target of link or url hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            return target;
        }

        // start glow sequence on an element
        function glowElement(element) {
            const startGlow = function() {
                onGlowEnd();
                element.dataset.glow = 'true';
                element.addEventListener('animationend', onGlowEnd);
            };
            const onGlowEnd = function() {
                element.removeAttribute('data-glow');
                element.removeEventListener('animationend', onGlowEnd);
            };
            startGlow();
        }

        // highlight link and all others with same target
        function highlight(link) {
            // force unhighlight all to start fresh
            unhighlightAll();

            // get links with same target
            if (!link)
                return;
            const sameLinks = getSameLinks(link);

            // if link unique and option is off, exit and don't highlight
            if (sameLinks.length <= 1 && options.highlightUnique !== 'true')
                return;

            // highlight all same links, and "select" (special highlight) this
            // one
            for (const sameLink of sameLinks) {
                if (sameLink === link)
                    sameLink.setAttribute('data-selected', 'true');
                else
                    sameLink.setAttribute('data-highlighted', 'true');
            }
        }

        // unhighlight all links
        function unhighlightAll() {
            const links = getLinks();
            for (const link of links) {
                link.setAttribute('data-selected', 'false');
                link.setAttribute('data-highlighted', 'false');
            }
        }

        // get links with same target
        function getSameLinks(link) {
            const results = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    results.push(otherLink);
            }
            return results;
        }

        // get all links of types we wish to handle
        function getLinks() {
            let query = 'a';
            if (options.externalLinks !== 'true')
                query += '[href^="#"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelectorAll(query);
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- table of contents plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin provides a "table of contents" (toc) panel on
        // the side of the document that allows the user to conveniently
        // navigate between sections of the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tableOfContents';

        // default plugin options
        const options = {
            // which types of elements to add links for, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3',
            // whether default behavior is to be closed ('false'), open
            // ('true'), or only open when screen wide enough to fit panel
            // ('auto'). note: still always starts closed when page loads.
            open: 'auto',
            // if list item is more than this many characters, text will be
            // truncated
            charLimit: '50',
            // whether or not to show bullets next to each toc item
            bullets: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // make toc panel and populate with entries (links to document
            // sections)
            const panel = makePanel();
            if (!panel)
                return;
            makeEntries(panel);
            document.body.insertBefore(panel, document.body.firstChild);

            closePanel();

            // attach click, scroll, and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('scroll', onScroll);
            window.addEventListener('hashchange', onScroll);
            window.addEventListener('keyup', onKeyUp);
            onScroll();

            // add class to push document body down out of way of toc button
            document.body.classList.add('toc_body_nudge');
        }

        // determine if screen wide enough to fit toc panel
        function isSmallScreen() {
            // in default theme:
            // 816px = 8.5in = width of "page" (<body>) element
            // 260px = min width of toc panel (*2 for both sides of <body>)
            return window.innerWidth < 816 + 260 * 2;
        }

        // open/close panel based on option and screen size
        function openOrClosePanel() {
            if (
                options.open === 'true' ||
                (options.open === 'auto' && !isSmallScreen())
            )
                openPanel();
            else
                closePanel();
        }

        // when mouse is clicked anywhere in window
        function onClick() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                openOrClosePanel();
        }

        // when window is scrolled or hash changed
        function onScroll() {
            highlightViewed();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            // close on esc
            if (event.key === 'Escape')
                closePanel();
        }

        // find entry of currently viewed document section in toc and highlight
        function highlightViewed() {
            const firstId = getFirstInView(options.typesQuery);

            // get toc entries (links), unhighlight all, then highlight viewed
            const list = document.getElementById('toc_list');
            if (!firstId || !list)
                return;
            const links = list.querySelectorAll('a');
            for (const link of links)
                link.dataset.viewing = 'false';
            const link = list.querySelector('a[href="#' + firstId + '"]');
            if (!link)
                return;
            link.dataset.viewing = 'true';
        }

        // get first or previous toc listed element in top half of view
        function getFirstInView(query) {
            // get all elements matching query and with id
            const elements = document.querySelectorAll(query);
            const elementsWithIds = [];
            for (const element of elements) {
                if (element.id)
                    elementsWithIds.push(element);
            }


            // get first or previous element in top half of view
            for (let i = 0; i < elementsWithIds.length; i++) {
                const element = elementsWithIds[i];
                const prevElement = elementsWithIds[Math.max(0, i - 1)];
                if (element.getBoundingClientRect().top >= 0) {
                    if (
                        element.getBoundingClientRect().top <
                        window.innerHeight / 2
                    )
                        return element.id;
                    else
                        return prevElement.id;
                }
            }
        }

        // make panel
        function makePanel() {
            // create panel
            const panel = document.createElement('div');
            panel.id = 'toc_panel';
            if (options.bullets === 'true')
                panel.dataset.bullets = 'true';

            // create header
            const header = document.createElement('div');
            header.id = 'toc_header';

            // create toc button
            const button = document.createElement('button');
            button.id = 'toc_button';
            button.innerHTML = document.querySelector(
                '.icon_th_list'
            ).innerHTML;
            button.classList.add('icon_button');

            // create header text
            const text = document.createElement('h3');
            text.innerHTML = 'Table of Contents';

            // create container for toc list
            const list = document.createElement('div');
            list.id = 'toc_list';

            // attach click listeners
            panel.addEventListener('click', onPanelClick);
            header.addEventListener('click', onHeaderClick);
            button.addEventListener('click', onButtonClick);

            // attach elements
            header.appendChild(button);
            header.appendChild(text);
            panel.appendChild(header);
            panel.appendChild(list);

            return panel;
        }

        // create toc entries (links) to each element of the specified types
        function makeEntries(panel) {
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements) {
                // do not add link if element doesn't have assigned id
                if (!element.id)
                    continue;

                // create link/list item
                const link = document.createElement('a');
                link.classList.add('toc_link');
                switch (element.tagName.toLowerCase()) {
                    case 'h1':
                        link.dataset.level = '1';
                        break;
                    case 'h2':
                        link.dataset.level = '2';
                        break;
                    case 'h3':
                        link.dataset.level = '3';
                        break;
                    case 'h4':
                        link.dataset.level = '4';
                        break;
                }
                link.title = element.innerText;
                let text = element.innerText;
                if (text.length > options.charLimit)
                    text = text.slice(0, options.charLimit) + '...';
                link.innerHTML = text;
                link.href = '#' + element.id;
                link.addEventListener('click', onLinkClick);

                // attach link
                panel.querySelector('#toc_list').appendChild(link);
            }
        }

        // when panel is clicked
        function onPanelClick(event) {
            // stop click from propagating to window/document and closing panel
            event.stopPropagation();
        }

        // when header itself is clicked
        function onHeaderClick(event) {
            togglePanel();
        }

        // when button is clicked
        function onButtonClick(event) {
            togglePanel();
            // stop header underneath button from also being clicked
            event.stopPropagation();
        }

        // when link is clicked
        function onLinkClick() {
            openOrClosePanel();
        }

        // open panel if closed, close if opened
        function togglePanel() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                closePanel();
            else
                openPanel();
        }

        // open panel
        function openPanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'true';
        }

        // close panel
        function closePanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'false';
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- th list icon -->

<template class="icon_th_list">
    <!-- modified from: https://fontawesome.com/icons/th-list -->
    <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
        <path
            fill="currentColor"
            d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- lightbox plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user clicks on an
        // image, the image fills the screen and the user can pan/drag/zoom
        // the image and navigate between other images in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'lightbox';

        // default plugin options
        const options = {
            // list of possible zoom/scale factors
            zoomSteps:
                '0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1,' +
                '1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8',
            // whether to fit image to view ('fit'), display at 100% and shrink
            // if necessary ('shrink'), or always display at 100% ('100')
            defaultZoom: 'fit',
            // whether to zoom in/out toward center of view ('true') or mouse
            // ('false')
            centerZoom: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <img> element
            const imgs = document.querySelectorAll('figure > img');
            let count = 1;
            for (const img of imgs) {
                img.classList.add('lightbox_document_img');
                img.dataset.number = count;
                img.dataset.total = imgs.length;
                img.addEventListener('click', openLightbox);
                count++;
            }

            // attach mouse and key listeners to window
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('keyup', onKeyUp);
        }

        // when mouse is moved anywhere in window
        function onWindowMouseMove(event) {
            window.mouseX = event.clientX;
            window.mouseY = event.clientY;
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'lightbox_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'lightbox_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeLightbox();
                    break;
            }
        }

        // open lightbox
        function openLightbox() {
            const lightbox = makeLightbox(this);
            if (!lightbox)
                return;

            blurBody(lightbox);
            document.body.appendChild(lightbox);
        }

        // make lightbox
        function makeLightbox(img) {
            // delete lightbox if it exists, start fresh
            closeLightbox();

            // create screen overlay containing lightbox
            const overlay = document.createElement('div');
            overlay.id = 'lightbox_overlay';

            // create image info boxes
            const numberInfo = document.createElement('div');
            const zoomInfo = document.createElement('div');
            numberInfo.id = 'lightbox_number_info';
            zoomInfo.id = 'lightbox_zoom_info';

            // create container for image
            const imageContainer = document.createElement('div');
            imageContainer.id = 'lightbox_image_container';
            const lightboxImg = makeLightboxImg(
                img,
                imageContainer,
                numberInfo,
                zoomInfo
            );
            imageContainer.appendChild(lightboxImg);

            // create bottom container for caption and navigation buttons
            const bottomContainer = document.createElement('div');
            bottomContainer.id = 'lightbox_bottom_container';
            const caption = makeCaption(img);
            const prevButton = makePrevButton(img);
            const nextButton = makeNextButton(img);
            bottomContainer.appendChild(prevButton);
            bottomContainer.appendChild(caption);
            bottomContainer.appendChild(nextButton);

            // attach top middle and bottom to overlay
            overlay.appendChild(numberInfo);
            overlay.appendChild(zoomInfo);
            overlay.appendChild(imageContainer);
            overlay.appendChild(bottomContainer);

            return overlay;
        }

        // make <img> object that is intuitively draggable and zoomable
        function makeLightboxImg(
            sourceImg,
            container,
            numberInfoBox,
            zoomInfoBox
        ) {
            // create copy of source <img>
            const img = sourceImg.cloneNode(true);
            img.classList.remove('lightbox_document_img');
            img.removeAttribute('id');
            img.removeAttribute('width');
            img.removeAttribute('height');
            img.style.position = 'unset';
            img.style.margin = '0';
            img.style.padding = '0';
            img.style.width = '';
            img.style.height = '';
            img.style.minWidth = '';
            img.style.minHeight = '';
            img.style.maxWidth = '';
            img.style.maxHeight = '';
            img.id = 'lightbox_img';

            // build sorted list of unique zoomSteps, always including a 100%
            let zoomSteps = [];
            const optionsZooms = options.zoomSteps.split(/[^0-9.]/);
            for (const optionZoom of optionsZooms) {
                const newZoom = parseFloat(optionZoom);
                if (newZoom && !zoomSteps.includes(newZoom))
                    zoomSteps.push(newZoom);
            }
            if (!zoomSteps.includes(1))
                zoomSteps.push(1);
            zoomSteps = zoomSteps.sort(function sortNumber(a, b) {
                return a - b;
            });

            // <img> object property variables
            let zoom = 1;
            let translateX = 0;
            let translateY = 0;
            let clickMouseX = undefined;
            let clickMouseY = undefined;
            let clickTranslateX = undefined;
            let clickTranslateY = undefined;

            updateNumberInfo();

            // update image numbers displayed in info box
            function updateNumberInfo() {
                numberInfoBox.innerHTML =
                    sourceImg.dataset.number + ' of ' + sourceImg.dataset.total;
            }

            // update zoom displayed in info box
            function updateZoomInfo() {
                let zoomInfo = zoom * 100;
                if (!Number.isInteger(zoomInfo))
                    zoomInfo = zoomInfo.toFixed(2);
                zoomInfoBox.innerHTML = zoomInfo + '%';
            }

            // move to closest zoom step above current zoom
            const zoomIn = function() {
                for (const zoomStep of zoomSteps) {
                    if (zoomStep > zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                updateTransform();
            };

            // move to closest zoom step above current zoom
            const zoomOut = function() {
                zoomSteps.reverse();
                for (const zoomStep of zoomSteps) {
                    if (zoomStep < zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                zoomSteps.reverse();

                updateTransform();
            };

            // update display of <img> based on scale/translate properties
            const updateTransform = function() {
                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                // get new width/height after scale
                const rect = img.getBoundingClientRect();
                // limit translate
                translateX = Math.max(translateX, -rect.width / 2);
                translateX = Math.min(translateX, rect.width / 2);
                translateY = Math.max(translateY, -rect.height / 2);
                translateY = Math.min(translateY, rect.height / 2);

                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                updateZoomInfo();
            };

            // fit <img> to container
            const fit = function() {
                // no x/y offset, 100% zoom by default
                translateX = 0;
                translateY = 0;
                zoom = 1;

                // widths of <img> and container
                const imgWidth = img.naturalWidth;
                const imgHeight = img.naturalHeight;
                const containerWidth = parseFloat(
                    window.getComputedStyle(container).width
                );
                const containerHeight = parseFloat(
                    window.getComputedStyle(container).height
                );

                // how much zooming is needed to fit <img> to container
                const xRatio = imgWidth / containerWidth;
                const yRatio = imgHeight / containerHeight;
                const maxRatio = Math.max(xRatio, yRatio);
                const newZoom = 1 / maxRatio;

                // fit <img> to container according to option
                if (options.defaultZoom === 'shrink') {
                    if (maxRatio > 1)
                        zoom = newZoom;
                } else if (options.defaultZoom === 'fit')
                    zoom = newZoom;

                updateTransform();
            };

            // when mouse wheel is rolled anywhere in container
            const onContainerWheel = function(event) {
                if (!event)
                    return;

                // let ctrl + mouse wheel to zoom behave as normal
                if (event.ctrlKey)
                    return;

                // prevent normal scroll behavior
                event.preventDefault();
                event.stopPropagation();

                // point around which to scale img
                const viewRect = container.getBoundingClientRect();
                const viewX = (viewRect.left + viewRect.right) / 2;
                const viewY = (viewRect.top + viewRect.bottom) / 2;
                const originX = options.centerZoom === 'true' ? viewX : mouseX;
                const originY = options.centerZoom === 'true' ? viewY : mouseY;

                // get point on image under origin
                const oldRect = img.getBoundingClientRect();
                const oldPercentX = (originX - oldRect.left) / oldRect.width;
                const oldPercentY = (originY - oldRect.top) / oldRect.height;

                // increment/decrement zoom
                if (event.deltaY < 0)
                    zoomIn();
                if (event.deltaY > 0)
                    zoomOut();

                // get offset between previous image point and origin
                const newRect = img.getBoundingClientRect();
                const offsetX =
                    originX - (newRect.left + newRect.width * oldPercentX);
                const offsetY =
                    originY - (newRect.top + newRect.height * oldPercentY);

                // translate image to keep image point under origin
                translateX += offsetX;
                translateY += offsetY;

                // perform translate
                updateTransform();
            };

            // when container is clicked
            function onContainerClick(event) {
                // if container itself is target of click, and not other
                // element above it
                if (event.target === this)
                    closeLightbox();
            }

            // when mouse button is pressed on image
            const onImageMouseDown = function(event) {
                // store original mouse position relative to image
                clickMouseX = window.mouseX;
                clickMouseY = window.mouseY;
                clickTranslateX = translateX;
                clickTranslateY = translateY;
                event.stopPropagation();
                event.preventDefault();
            };

            // when mouse button is released anywhere in window
            const onWindowMouseUp = function(event) {
                // reset original mouse position
                clickMouseX = undefined;
                clickMouseY = undefined;
                clickTranslateX = undefined;
                clickTranslateY = undefined;

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mouseup', onWindowMouseUp);
            };

            // when mouse is moved anywhere in window
            const onWindowMouseMove = function(event) {
                if (
                    clickMouseX === undefined ||
                    clickMouseY === undefined ||
                    clickTranslateX === undefined ||
                    clickTranslateY === undefined
                )
                    return;

                // offset image based on original and current mouse position
                translateX = clickTranslateX + window.mouseX - clickMouseX;
                translateY = clickTranslateY + window.mouseY - clickMouseY;
                updateTransform();
                event.preventDefault();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mousemove', onWindowMouseMove);
            };

            // when window is resized
            const onWindowResize = function(event) {
                fit();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('resize', onWindowResize);
            };

            // attach the necessary event listeners
            img.addEventListener('dblclick', fit);
            img.addEventListener('mousedown', onImageMouseDown);
            container.addEventListener('wheel', onContainerWheel);
            container.addEventListener('mousedown', onContainerClick);
            container.addEventListener('touchstart', onContainerClick);
            window.addEventListener('mouseup', onWindowMouseUp);
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('resize', onWindowResize);

            // run fit() after lightbox atttached to document and <img> Loaded
            // so needed container and img dimensions available
            img.addEventListener('load', fit);

            return img;
        }

        // make caption
        function makeCaption(img) {
            const caption = document.createElement('div');
            caption.id = 'lightbox_caption';
            const captionSource = img.nextElementSibling;
            if (captionSource.tagName.toLowerCase() === 'figcaption') {
                const captionCopy = makeCopy(captionSource);
                caption.innerHTML = captionCopy.innerHTML;
            }

            caption.addEventListener('touchstart', function(event) {
                event.stopPropagation();
            });

            return caption;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // make button to jump to previous image in document
        function makePrevButton(img) {
            const prevButton = document.createElement('button');
            prevButton.id = 'lightbox_prev_button';
            prevButton.title = 'Jump to the previous image in the document [←]';
            prevButton.classList.add('icon_button', 'lightbox_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;

            // attach click listeners to button
            prevButton.addEventListener('click', function() {
                getPrevImg(img).click();
            });

            return prevButton;
        }

        // make button to jump to next image in document
        function makeNextButton(img) {
            const nextButton = document.createElement('button');
            nextButton.id = 'lightbox_next_button';
            nextButton.title = 'Jump to the next image in the document [→]';
            nextButton.classList.add('icon_button', 'lightbox_button');
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;

            // attach click listeners to button
            nextButton.addEventListener('click', function() {
                getNextImg(img).click();
            });

            return nextButton;
        }

        // get previous image in document
        function getPrevImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if < 1
            if (index - 1 >= 0)
                index--;
            else
                index = imgs.length - 1;
            return imgs[index];
        }

        // get next image in document
        function getNextImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if > total
            if (index + 1 <= imgs.length - 1)
                index++;
            else
                index = 0;
            return imgs[index];
        }

        // close lightbox
        function closeLightbox() {
            focusBody();

            const lightbox = document.getElementById('lightbox_overlay');
            if (lightbox)
                lightbox.remove();
        }

        // make all elements behind lightbox non-focusable
        function blurBody(overlay) {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.tabIndex = -1;
            document.body.classList.add('body_no_scroll');
        }

        // make all elements focusable again
        function focusBody() {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.removeAttribute('tabIndex');
            document.body.classList.remove('body_no_scroll');
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- attributes plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows arbitrary HTML attributes to be attached
        // to (almost) any element. Place an HTML comment inside or next to the
        // desired element in the format <!-- $attribute="value" -->

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'attributes';

        // default plugin options
        const options = {
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // get list of comments in document
            const comments = findComments();

            for(const comment of comments)
                if (comment.parentElement)
                    addAttributes(
                        comment.parentElement,
                        comment.nodeValue.trim()
                    );
        }

        // add html attributes to specified element based on string of 
        // html attributes and values
        function addAttributes(element, text) {
            // regex's for finding attribute/value pairs in the format of
            // attribute="value" or attribute='value
            const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
            const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

            // loop through attribute/value pairs
            let match;
            while(match = text.match(regex2) || text.match(regex1)) {
                // get attribute and value from regex capture groups
                let attribute = match[1];
                let value = match[2];

                // remove from string
                text = text.substring(match.index + match[0].length);

                if (!attribute || !value)
                    break;

                // set attribute of parent element
                try {
                    element.setAttribute(attribute, value);
                } catch(error) {
                    console.log(error);
                }

                // special case for colspan
                if (attribute === 'colspan')
                    removeTableCells(element, value);
            }
        }

        // get list of comment elements in document
        function findComments() {
            const comments = [];

            // iterate over comment nodes in document
            function acceptNode(node) {
                return NodeFilter.FILTER_ACCEPT;
            }
            const iterator = document.createNodeIterator(
                document.body,
                NodeFilter.SHOW_COMMENT,
                acceptNode
            );
            let node;
            while(node = iterator.nextNode())
                comments.push(node);

            return comments;
        }

        // remove certain number of cells after specified cell
        function removeTableCells(cell, number) {
            number = parseInt(number);
            if (!number)
                return;

            // remove elements
            for(; number > 1; number--) {
                if (cell.nextElementSibling)
                    cell.nextElementSibling.remove();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- math plugin configuration -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "CommonHTML": { linebreaks: { automatic: true } },
        "HTML-CSS": { linebreaks: { automatic: true } },
        "SVG": { linebreaks: { automatic: true } },
        "fast-preview": { disabled: true }
    });
</script>

<!-- math plugin -->

<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML'>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'MathJax' allows the proper rendering of
    // math/equations written in LaTeX.

    // https://www.mathjax.org/
</script>
<!-- annotations plugin configuration -->

<script>
    window.hypothesisConfig = function() {
        return {
            branding: {
                accentColor: '#2196f3',
                appBackgroundColor: '#f8f8f8',
                ctaBackgroundColor: '#f8f8f8',
                ctaTextColor: '#000000',
                selectionFontFamily: 'Open Sans, Helvetica, sans serif',
                annotationFontFamily: 'Open Sans, Helvetica, sans serif'
            }
        };
    };
</script>

<!-- annotations plugin -->

<script src='https://hypothes.is/embed.js'>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'Hypothesis' allows public annotation of the
    // manuscript.

    // https://web.hypothes.is/
</script>
<!-- analytics plugin -->

<!-- copy and paste code from Google Analytics or similar service here -->
</body>
</html>
