## Identifying research gaps

Detection and diagnosis rely on clinicians[^2] searching for abnormalities in medical images.
Across many type of images (from light microscopy to magnetic resonance) and multiple ways to view them (e.g., via glass slides or computer workstations), clinicians are confronted with a set of similar perceptual and cognitive challenges.
Clinicians must bring to bear a vast amount of medical knowledge as well as contextual information about the patient (e.g., referring physician's information, prior report, prior medical history, genomics information) in order to interpret highly complex and variable images quickly and accurately.
This is a highly challenging endeavor.
Clinicians face many difficulties, from information overload to repeated interruptions to clinician burnout, that in turn are closely associated with health care quality, patient safety, and financial burdens on practices [@doi:10.1001/jamainternmed.2018.3713; @doi:10.1001/jamainternmed.2017.4340; @doi:10.1016/S0140-6736(09)61424-0].
Even under ideal circumstances, human observers are bound to make mistakes.
Errors, both false positives and false negatives, are a reality in both radiology [@doi:10.2214/AJR.06.1270; @doi:10.1016/j.clon.2016.05.003; @doi:10.1016/j.urolonc.2015.04.005] and pathology practice [@doi:10.1002/cncr.21431].
The majority of diagnostic errors in radiology can be traced to perceptual and cognitive factors (Berlin & Berlin, 1995; Smith, 1967).
The same is probably true in pathology, though there is much less research in this area (Raab et al., 2005).
Improving the accuracy of diagnosis requires an understanding of the perceptual and cognitive mechanisms underlying the performance of clinicians.
Additionally, cognitive and perceptual principles and approaches should be applied to address issues concerning clinicians' work environment and well-being.

What research should we encourage in order to improve clinicians' diagnostic accuracy, work environment, and well-being? The first challenge for the Think Tank participants was to identify the research gaps and critical unsolved problems in pathology and radiology, from the perspective of clinicians.
The primary challenges identified by the clinicians were information overload and integrating large amounts of information from various sources.

For example, the transition from the analog to digital eras has meant a qualitative change in the nature of the radiological problem.
A radiologist scrutinizing a single chest X-ray for a lung nodule is trying to extract a target with a very low signal:noise ratio (SNR) from a single image.
The same radiologist reading a chest CT is searching for a target with a fairly high SNR in a scan comprising thousands of images (slices).
In addition, the radiologist must now incorporate into her decision information from outside sources, such as electronic health records and genetic panels, that may not have been available in the past.
Furthermore, the decisions that clinicians have to make have gotten more complex as precision medicine has advanced.
A pathologist now might have to indicate not just whether something is a tumor or not, but if the tumor is hot or cold, likely to be responsive or non-responsive.
The cognitive capacity of the clinician, in contrast, has not changed, and the time pressure has only gotten worse.
What are the effects of information overload on medical decision making and decision quality? Are there technical solutions or decision-making aids or strategies that could be used to efficiently integrate complex information? For example, psychologically distancing oneself from information has been shown to improve non-medical decision-making (Fukukura et al., 2013).
What is the applicability of decision strategies to real world practice? The cognitive and perceptual challenges of the clinicians' role, and the implications for practice, are poorly understood at present.

Task shifting was another topic identified by the Think Tank participants.
Interruptions and distractions from a variety of sources (e.g., texts, email, pager, colleagues, telephone) may lead clinicians to miss or fail to report important findings.
Another form of task shifting is when clinicians move from case to case, different organs, while using various image modalities.
There is no research on whether task shifting in medical imaging creates adverse sequential consequences and/or how to mitigate these effects.

As one might expect from the above descriptions, the workload for clinicians has increased, and physical and mental fatigue of clinicians are at unprecedented levels, contributing to both perceptual and interpretive errors.
Fatigue can manifest as attention errors, such as when a clinician scrolls too fast through multi-slice or volumetric images, which may give the false impression that the clinician has sufficiently viewed the case.
Additional errors can result from lack of focus, getting easily distracted, and/or failing to record what is perceived.
These errors caused by physical and mental fatigue become more apparent at the end of the day.
Multiple studies have reported a decrease in detection accuracy due to fatigue (for a review, see Waite et al., 2017) but translational research needs to be conducted to mitigate fatigue effects in real world practice.

Interpretative errors can occur from a variety of sources.
For radiologists, several categories of tumors can be difficult to interpret, such as when there is a subtle gradient (i.e., when it is difficult to notice subtle changes or new lesions) from benign to malignant tumors, malignant to benign tumors, and when benign tumors mimic malignant tumors.
Additionally, it is also often difficult to interpret or connect two dissonant findings (e.g., adrenal nodule with a lung mass) and the clinician ends up failing to link findings and report a complete picture.
Research should focus on understanding the perceptual and cognitive underpinnings of these type of cases to help mitigate interpretation difficulty.

Artificial intelligence (AI) tools are often proposed as a solution to the challenges facing clinicians.
However, there is a mismatch between what clinicians need from AI and how AI is typically developed.
AI solutions are often pitched as "outperforming" the clinician, implying that AI systems are on the cusp of replacing the clinician (Mukherjee, 2017), or at least serving as an equivalent reader (McKinney et al., 2020).
This stems from an incomplete picture of the clinician's job.
A better approach would be to develop AI as a tool to automate the data reduction process, extracting the information that will aid the clinician's decision process.
For example, when reading pap smears, cytotechnologists can sign off on cases that are unequivocally negative, leaving the cytopathologists to focus only on cases with potential abnormalities.
AI could usefully fulfill this sort of role, and potentially automate quality assurance (QA) procedures.
A useful framework is the "diagnostic cockpit of the future", described by Krupinski et al.
(2019) as a set of tools to "aggregate, organize, and simplify medical imaging results and patient-centric clinical data." This metaphor underscores the role of AI in helping to winnow the information available to the clinician and present only the most clinically relevant information in the clearest way possible.
In order to accomplish these goals, AI should be developed within a broad interdisciplinary context.
Clinical, perceptual, and cognitive perspectives are all needed in the development process, rather than treated as an afterthought.

[^2]: Here we will use the word "clinicians" to refer to anyone tasked with reading a medical image. The typical clinician in this sense will be a radiologist or pathologist, but the term should be understood to include many other specialties such as nuclear medicine or dermatology, as well as non-specialists who read images as part of their practice.
